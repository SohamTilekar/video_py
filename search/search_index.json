{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"VidioPy","text":"<p>VidioPy is a Python library for video processing. It provides a simple API for common video processing tasks such as reading and writing video files, transforming video clips, performing basic operations like cuts, concatenations, and title insertions. It also supports video compositing (a.k.a. non-linear editing), advanced video effects, and video processing.</p>"},{"location":"#overview","title":"Overview","text":"<p>1.Download &amp; Install</p> <p>1.Getting Started</p> <p>1.Reference Manual</p>"},{"location":"#contributing","title":"Contributing","text":"<p>VidioPy is an open source project originally developed by Soham &amp; released under the MIT license. It is currently maintained by Soham. The code is hosted on Github, where you can push improvements, report bugs and ask for help. We welcome all kinds of contributions, from code to documentation, to bug reports. Please read the contribution guidelines first.</p>"},{"location":"getting_started/basic_concepts/","title":"Basic Concepts","text":"<p>VidioPY primarily works with two types of clips: <code>VideoClip</code> and <code>AudioClip</code>. Both are derived from the <code>Clip</code> base class and can be manipulated in various ways such as cutting, slowing down, darkening, or mixing with other clips to create new ones. These clips can then be exported to various file formats such as MP4, GIF, MP3, etc.</p> <pre><code>flowchart TB\n    Clip[Clip]\n    Clip --&gt;|inherits| VideoClip[VideoClip]\n    Clip --&gt;|inherits| AudioClip[AudioClip]\n    VideoClip --&gt;|inherits| ImageClip[ImageClip]\n    VideoClip --&gt;|inherits| VideoFileClip[VideoFileClip]\n    VideoClip --&gt;|inherits| ImageSequenceClip[ImageSequenceClip]\n    ImageClip --&gt;|inherits| Data2ImageClip[Data2ImageClip]\n    Data2ImageClip --&gt;|inherits| TextClip[TextClip]\n    Data2ImageClip --&gt;|inherits| ColorClip[ColorClip]\n    AudioClip --&gt;|inherits| SilenceClip[SilenceClip]\n    SilenceClip --&gt;|inherits| AudioFileClip[AudioFileClip]\n    AudioClip --&gt;|inherits| AudioArrayClip[AudioArrayClip]</code></pre> <p><code>VideoClip</code> instances can be created from a video file, an image, a text, or a custom animation, and can include an audio track, which is an <code>AudioClip</code>.</p> <p>VidioPY provides numerous effects that can be applied to a clip (e.g., <code>clip.resize(width=\"360\")</code>, <code>clip.subclip(t1,t2)</code>, or <code>clip.fx(vidiopy.brightness, 1.5)</code>). Additionally, VidioPY implements several functions (like <code>clip.fl_frame_transform</code>, <code>clip.fl_clip_transform</code>, <code>clip.fl_time_transform</code>, <code>clip.fx</code>, etc.) that make it easy to create custom effects.</p>"},{"location":"getting_started/basic_concepts/#videoclip","title":"VideoClip","text":""},{"location":"getting_started/basic_concepts/#creating-a-videoclip","title":"Creating a VideoClip","text":"<p>A <code>VideoClip</code> can be created in several ways. The most common method is to load a video file using <code>VideoFileClip</code>:</p> <pre><code>from vidiopy import VideoFileClip\nclip = VideoFileClip(\"path/to/video.mp4\")\n</code></pre> <p>A VideoClip can also be created from an image:</p> <pre><code>from vidiopy import ImageClip\nclip = ImageClip(\"path/to/image.png\")\n</code></pre>"},{"location":"getting_started/basic_concepts/#modifying-a-videoclip","title":"Modifying a VideoClip","text":"<p>A <code>VideoClip</code> has several attributes such as fps, duration, size, audio, start, end, etc. These can be modified using the corresponding <code>set</code> methods:</p> <pre><code>clip = clip.set_duration(10) # Not Allowed for the VideoClips only for the ImageClips\nclip = clip.set_fps(24) # Should be int or float\nclip = clip.set_start(5) # Use Full for the Compositing &amp; Concatenating Video Clip. More in the Mixing clips Section\nclip = clip.set_end(15) # Use Full for the Compositing &amp; Concatenating Video Clip. More in the Mixing clips Section\naudio = AudioClip(\"path/to/audio.mp3\")\nclip = clip.set_audio(audio) # Set the audio of the clip. use full for the ImageClips.\n...\n</code></pre>"},{"location":"getting_started/basic_concepts/#applying-effects-to-a-videoclip","title":"Applying Effects to a VideoClip","text":"<p>Various effects can be applied to a VideoClip, including resize, crop, subclip, fx, etc.:</p> <pre><code>clip = resize(clip, width=360) # Resize the clip to the given width\nclip = crop(clip, x1=10, y1=10, x2=100, y2=100) # Crop the clip to the given dimensions\nclip = clip.subclip(t1=5, t2=10) # Cut the clip to the given duration\nclip = clip.fx(vidiopy.brightness, 1.5) # Apply the brightness effect to the clip\n...\n</code></pre>"},{"location":"getting_started/basic_concepts/#exporting-a-videoclip","title":"Exporting a VideoClip","text":"<p>A <code>VideoClip</code> can be exported to a file using the <code>write_videofile</code> method:</p> <pre><code>clip.write_videofile(\"path/to/output/video.mp4\") # Write the clip to a file\nclip.write_videofile_subclip(\"path/to/output/video.mp4\", start_t=5, end_t=10) # Write the subclip to a file\nclip.write_image_sequence(nformat=\".png\", dir=\"images\") # Write the clip to a file as an image sequence\nclip.save_frame(\"path/to/output/frame.png\", t=5) # Save the frame of the clip to a file\n</code></pre>"},{"location":"getting_started/basic_concepts/#imageclip","title":"ImageClip","text":""},{"location":"getting_started/basic_concepts/#creating-an-imageclip","title":"Creating an ImageClip","text":"<p>An <code>ImageClip</code> can be created by loading an image file using <code>ImageClip</code> or by creating a new image using <code>Image.new</code> or a numpy array:</p> <pre><code>from vidiopy import ImageClip\nfrom PIL import Image\nimport numpy as np\nclip = ImageClip(\"path/to/image.png\", fps=24, duration=10) # Create an image clip from a file\nclip2 = ImageClip(Image.new(\"RGB\", (720, 480), (0, 0, 0)), fps=24, duration=10) # Create an image clip from a PIL image\nclip3 = ImageClip(np.zeros((480, 720, 3), dtype=np.uint8), fps=24, duration=10) # Create an image clip from a numpy array\n</code></pre>"},{"location":"getting_started/basic_concepts/#applying-effects-to-a-imageclip","title":"applying Effects to a ImageClip","text":"<p>All Effects that can be applied to the <code>VideoClip</code> can be applied to the <code>ImageClip</code> but it is bit different. Some effects you can apply directly to the <code>ImageClip</code> like the Video Clip but Some Cant Directly for that you have to convert the <code>ImageClip</code> to the <code>VideoClip</code> and then apply the effect:</p> <pre><code>from vidiopy import ImageClip\nclip = ImageClip(\"path/to/image.png\", fps=24, duration=10) # Create an image clip from a file\nclip = clip.resize(width=360) # Resize the clip to the given width\nclip = clip.to_video_clip() # Convert the ImageClip to the VideoClip\nclip = clip.fx(accel_decel, 0.5) # Apply the accel_decel effect to the clip\n</code></pre>"},{"location":"getting_started/basic_concepts/#audioclip","title":"AudioClip","text":""},{"location":"getting_started/basic_concepts/#creating-an-audioclip","title":"Creating an AudioClip","text":"<p>An <code>AudioClip</code> can be created by loading an audio file using <code>AudioFileClip</code> or <code>SilenceClip</code>:</p> <pre><code>from vidiopy import AudioFileClip\nclip = AudioFileClip(\"path/to/audio.mp3\") # Create an audio clip from a file Also accept video file it will extract the audio from the video file\nclip = SilenceClip(duration=10) # Create a silent audio clip\n</code></pre>"},{"location":"getting_started/basic_concepts/#modifying-an-audioclip","title":"Modifying an AudioClip","text":"<p>An <code>AudioClip</code> has several attributes such as audio_data, fps, start, end, etc. These can be modified using the corresponding <code>set</code> methods:</p> <pre><code>clip.fps = 24 # Set the fps of the clip\nclip.start = 5 # Set the start time of the clip\nclip.end = 15 # Set the end time of the clip\nclip.audio_data = audio_data # Set the audio data of the clip\n...\n</code></pre>"},{"location":"getting_started/basic_concepts/#applying-effects-to-an-audioclip","title":"Applying Effects to an AudioClip","text":"<p>An <code>AudioClip</code> has several attributes such as audio_data, fps, start, end, etc. These can be modified using the corresponding set methods:</p> <pre><code>clip = clip.sub_clip(start=5, end=10) # Cut the clip to the given duration\nclip = audio_normalize(clip) # Apply the normalize effect to the clip\n...\n</code></pre>"},{"location":"getting_started/basic_concepts/#exporting-an-audioclip","title":"Exporting an AudioClip","text":"<p>An <code>AudioClip</code> can be exported to a file using the <code>write_audiofile</code> method:</p> <pre><code>clip.write_audiofile(\"path/to/output/audio.mp3\") # Write the clip to a file\n</code></pre>"},{"location":"getting_started/basic_concepts/#final-flowchart","title":"Final Flowchart","text":"<pre><code>graph TD\n    Start((Start)) --&gt; ChooseClipType[Choose Clip Type]\n    ChooseClipType --&gt; |VideoClip| CreateVideoClip[Create VideoClip]\n    ChooseClipType --&gt; |ImageClip| CreateImageClip[Create ImageClip]\n    ChooseClipType --&gt; |AudioClip| CreateAudioClip[Create AudioClip]\n    CreateVideoClip --&gt; |Load from file| LoadVideoFile[\"Load from file\"]\n    CreateVideoClip --&gt; |Create from image| CreateVideoFromImage[\"Create from image\"]\n    LoadVideoFile --&gt; ModifyVideoClip[Modify VideoClip]\n    CreateVideoFromImage --&gt; ModifyVideoClip\n    ModifyVideoClip --&gt; |Set duration| SetDuration[\"Set duration\"]\n    ModifyVideoClip --&gt; |Set FPS| SetFPS[\"Set FPS\"]\n    ModifyVideoClip --&gt; |Set start/end| SetStartEnd[\"Set start/end\"]\n    ModifyVideoClip --&gt; |Set audio| SetAudio[\"Set audio\"]\n    ModifyVideoClip --&gt; ApplyEffectsToVideo[Apply Effects to VideoClip]\n    ApplyEffectsToVideo --&gt; |Resize| ResizeClip[\"Resize\"]\n    ApplyEffectsToVideo --&gt; |Crop| CropClip[\"Crop\"]\n    ApplyEffectsToVideo --&gt; |Subclip| Subclip[\"Subclip\"]\n    ApplyEffectsToVideo --&gt; |Apply custom effects| CustomEffects[\"Apply custom effects\"]\n    ApplyEffectsToVideo --&gt; ExportVideoClip[Export VideoClip]\n    ExportVideoClip --&gt; |Write to video file| WriteVideoFile[\"Write to video file\"]\n    ExportVideoClip --&gt; |Write subclip to video file| WriteSubclip[\"Write subclip to video file\"]\n    ExportVideoClip --&gt; |Write as image sequence| WriteImageSequence[\"Write as image sequence\"]\n    ExportVideoClip --&gt; |Save frame| SaveFrame[\"Save frame\"]\n    CreateImageClip --&gt; |Load from file| LoadImageFile[\"Load from file\"]\n    CreateImageClip --&gt; |Create from PIL image| CreateFromPIL[\"Create from PIL image\"]\n    CreateImageClip --&gt; |Create from numpy array| CreateFromNumpy[\"Create from numpy array\"]\n    LoadImageFile --&gt; ModifyImageClip[Modify ImageClip]\n    CreateFromPIL --&gt; ModifyImageClip\n    CreateFromNumpy --&gt; ModifyImageClip\n    ModifyImageClip --&gt; |Resize| ResizeImageClip[\"Resize\"]\n    ModifyImageClip --&gt; ConvertToVideo[Convert to VideoClip and apply effects]\n    ResizeImageClip --&gt; ConvertToVideo\n    ConvertToVideo --&gt; |Apply effects| ApplyEffectsToVideo\n    ApplyEffectsToVideo --&gt; ExportImageClip[Export ImageClip]\n    ExportImageClip --&gt; WriteVideoFile\n    ExportImageClip --&gt; WriteSubclip\n    ExportImageClip --&gt; WriteImageSequence\n    ExportImageClip --&gt; SaveFrame\n    CreateAudioClip --&gt; |Load from file| LoadAudioFile[\"Load from file\"]\n    CreateAudioClip --&gt; |Create silent clip| CreateSilentClip[\"Create silent clip\"]\n    LoadAudioFile --&gt; ModifyAudioClip[Modify AudioClip]\n    CreateSilentClip --&gt; ModifyAudioClip\n    ModifyAudioClip --&gt; |Set FPS| SetFPS_audio[\"Set FPS\"]\n    ModifyAudioClip --&gt; |Set start/end| SetStartEnd_audio[\"Set start/end\"]\n    ModifyAudioClip --&gt; |Set audio data| SetAudioData[\"Set audio data\"]\n    ModifyAudioClip --&gt; ApplyEffectsToAudio[Apply Effects to AudioClip]\n    ApplyEffectsToAudio --&gt; |Subclip| Subclip_audio[\"Subclip\"]\n    ApplyEffectsToAudio --&gt; |Apply normalize effect| NormalizeEffect[\"Apply normalize effect\"]\n    ApplyEffectsToAudio --&gt; ExportAudioClip[Export AudioClip]\n    ExportAudioClip --&gt; WriteAudioFile[\"Write to audio file\"]\n    WriteVideoFile --&gt; End((End))\n    WriteSubclip --&gt; End\n    WriteImageSequence --&gt; End\n    SaveFrame --&gt; End\n    WriteAudioFile --&gt; End\n\n    click Start \"#\"\n    click ChooseClipType \"#basic-concepts\"\n    click CreateVideoClip \"#creating-a-videoclip\"\n    click LoadVideoFile \"#creating-a-videoclip\"\n    click ModifyVideoClip \"#modifying-a-videoclip\"\n    click CreateVideoFromImage \"#creating-a-videoclip\"\n    click SetDuration \"#modifying-a-videoclip\"\n    click SetFPS \"#modifying-a-videoclip\"\n    click SetStartEnd \"#modifying-a-videoclip\"\n    click SetAudio \"#modifying-a-videoclip\"\n    click ApplyEffectsToVideo \"#applying-effects-to-a-videoclip\"\n    click ResizeClip \"#applying-effects-to-a-videoclip\"\n    click CropClip \"#applying-effects-to-a-videoclip\"\n    click Subclip \"#applying-effects-to-a-videoclip\"\n    click CustomEffects \"#applying-effects-to-a-videoclip\"\n    click ExportVideoClip \"#exporting-a-videoclip\"\n    click WriteVideoFile \"#exporting-a-videoclip\"\n    click WriteSubclip \"#exporting-a-videoclip\"\n    click WriteImageSequence \"#exporting-a-videoclip\"\n    click SaveFrame \"#exporting-a-videoclip\"\n    click CreateImageClip \"#creating-an-imageclip\"\n    click LoadImageFile \"#creating-an-imageclip\"\n    click ModifyImageClip \"#modifying-an-imageclip\"\n    click CreateFromPIL \"#creating-an-imageclip\"\n    click CreateFromNumpy \"#creating-an-imageclip\"\n    click ResizeImageClip \"#modifying-an-imageclip\"\n    click ConvertToVideo \"#modifying-an-imageclip\"\n    click ApplyEffectsToVideo \"#applying-effects-to-a-imageclip\"\n    click ExportImageClip \"#exporting-an-imageclip\"\n    click WriteVideoFile \"#exporting-an-imageclip\"\n    click WriteSubclip \"#exporting-an-imageclip\"\n    click WriteImageSequence \"#exporting-an-imageclip\"\n    click SaveFrame \"#exporting-an-imageclip\"\n    click CreateAudioClip \"#creating-an-audioclip\"\n    click LoadAudioFile \"#creating-an-audioclip\"\n    click ModifyAudioClip \"#modifying-an-audioclip\"\n    click CreateSilentClip \"#creating-an-audioclip\"\n    click SetFPS_audio \"#modifying-an-audioclip\"\n    click SetStartEnd_audio \"#modifying-an-audioclip\"\n    click SetAudioData \"#modifying-an-audioclip\"\n    click ApplyEffectsToAudio \"#applying-effects-to-an-audioclip\"\n    click Subclip_audio \"#applying-effects-to-an-audioclip\"\n    click NormalizeEffect \"#applying-effects-to-an-audioclip\"\n    click ExportAudioClip \"#exporting-an-audioclip\"\n    click WriteAudioFile \"#exporting-an-audioclip\"\n    click End \"#final-flowchart\"</code></pre>"},{"location":"getting_started/download_install/","title":"Download and Installation","text":""},{"location":"getting_started/download_install/#installation","title":"Installation","text":""},{"location":"getting_started/download_install/#using-pip","title":"Using pip","text":"<p>If you're utilizing pip, installation is a breeze. Just execute the following command:</p> <pre><code>pip install vidiopy\n</code></pre> Warning: Requires setuptools <p>In case setuptools isn't installed, rectify this by using: <pre><code>pip install setuptools\n</code></pre></p>"},{"location":"getting_started/download_install/#using-source","title":"Using Source","text":"<ol> <li>Download the source code from the GitHub repository.</li> <li>Unzip the downloaded file into a designated folder.</li> <li>Run the following command in the terminal:</li> </ol> <pre><code>python setup.py install\n</code></pre>"},{"location":"getting_started/download_install/#dependencies","title":"Dependencies","text":"<p>VidioPy relies on the following Python packages:</p> <ul> <li> <p>rich (1)</p> </li> <li> <p>numpy (2)</p> </li> <li> <p>ffmpegio (3)</p> </li> <li> <p>pillow (4)</p> </li> </ul> <ol> <li>rich is a Python library for rich text and beautiful formatting in the terminal. It is used for displaying progress bars and other rich text in the terminal.</li> <li>numpy is a Python library for numerical computing. It is used for handling arrays and matrices.</li> <li>ffmpegio is a Python library for reading and writing video files using ffmpeg. It is used for reading and writing video files.</li> <li>pillow is a Python library for image processing. It is used for reading, writing and modifying image files.</li> </ol> <p>Pip will automatically install these dependencies for you during installation. If installing from source, manual installation of these dependencies is required.</p> <p>VidioPy also depends on ffmpeg and ffprobe. It will attempt to download these binaries globally or place them in the <code>vidiopy/binary</code> directory if not found in the system's PATH or global variables. If the automatic download fails, you can manually download them from here and place them in the <code>vidiopy/binary</code> folder or set them in global variables.</p> <p>For those who prefer more control over paths, you can specify the locations of ffmpeg and ffprobe using the <code>vidiopy.set_path()</code> function after importing vidiopy:</p> <pre><code>import vidiopy\nvidiopy.set_path(ffmpeg_path=\"path/to/ffmpeg\", ffprobe_path=\"path/to/ffprobe\")\n</code></pre> <p>Alternatively, you can pass the path of the folder containing ffmpeg and ffprobe:</p> <pre><code>import vidiopy\nvidiopy.set_path(ffmpeg_path=\"path/to/folder/containing/ffmpeg &amp; ffprobe\")\n</code></pre>"},{"location":"getting_started/mixing_clip/","title":"Mixing clips","text":"<p>Video composition, also known as non-linear editing, is the fact of playing several clips together in a new clip. This video is a good example of what compositing you can do with VidioPy:</p>"},{"location":"getting_started/mixing_clip/#compositing-concatenating-clips","title":"compositing / Concatenating clips","text":"<p>Two simple ways of putting clips together is to concatenate them (to play them one after the other in a single long clip) or to compositing (to them side by side in a single larger clip).</p>"},{"location":"getting_started/mixing_clip/#concatenating-clips","title":"Concatenating clips","text":"<p>Concatenating means playing the clips one after the other in a single long clip. The function <code>concatenate_videoclips</code> takes a list of clips and returns a new clip that is the concatenation of all the clips in the list. Concatenation is done with the function <code>concatenate_videoclips</code>:</p> <pre><code>from vidiopy import VideoFileClip, ImageClip, concatenate_videoclips\nclip1 = VideoFileClip(\"video.mp4\").subclip(0,5)\nclip2 = ImageClip(\"image.jpg\").set_duration(5)\nf_clip = concatenate_videoclips([clip1,clip2], fps=24, over_scale=True)\nf_clip.write_videofile(\"output.mp4\")\n</code></pre> <p>The f_clip is a clip that plays the clips 1, and 2 one after the other. Note that the clips do not need to be the same size. If they aren't they will all appear centered in a clip large enough to contain the biggest of them, with optionally a color of your choosing to fill the borders. You have many other options there (see the doc of the function).</p>"},{"location":"getting_started/mixing_clip/#compositing-clip","title":"Compositing Clip","text":"<p>Compositing is done with the function <code>composite_videoclips</code>:</p> <pre><code>video = CompositeVideoClip([clip1,clip2,clip3])\n</code></pre> <p>Now video plays <code>clip1</code>, and <code>clip2</code> on top of <code>clip1</code>, and <code>clip3</code> on top of <code>clip1</code>, and <code>clip2</code>. For instance, if <code>clip2</code> and <code>clip3</code> have the same size as <code>clip1</code>, then only <code>clip3</code>, which is on top, will be visible in the video\u2026 unless <code>clip3</code> and clip2 have masks which hide parts of them. Note that by default the composition has the size of the largest clip or first if <code>bg_clip=True</code>.</p>"},{"location":"getting_started/mixing_clip/#starting-and-stopping-times","title":"Starting and stopping times","text":"<p>In a CompositionClip, all the clips start to play at a time that is specified by the clip.start attribute. You can set this starting time as follows:</p> <p>clip1 = clip1.with_start(5) # start after 5 seconds So for instance your composition will look like</p> <pre><code>video = CompositeVideoClip([clip1, # starts at t=0\n                            clip2.with_start(5), # start at t=5s\n                            clip3.with_start(9)]) # start at t=9s\n</code></pre> <p>In the example above, maybe clip2 will start before clip1 is over.</p>"},{"location":"getting_started/mixing_clip/#positioning-clips","title":"Positioning clips","text":"<p>If clip2 and clip3 are smaller than clip1, you can decide where they will appear in the composition by setting their position. Here we indicate the coordinates of the top-left pixel of the clips:</p> <pre><code>video = CompositeVideoClip([clip1,\n                           clip2.with_position((45,150)),\n                           clip3.with_position((90,100))])\n</code></pre> <p>There are many ways to specify the position:</p> <pre><code>clip2.with_position((45,150)) # x=45, y=150 , in pixels\n\nclip2.with_position(\"center\") # automatically centered\n\n# clip2 is horizontally centered, and at the top of the picture\nclip2.with_position((\"center\",\"top\"))\n\n# clip2 is vertically centered, at the left of the picture\nclip2.with_position((\"left\",\"center\"))\n\n# clip2 is at 40% of the width, 70% of the height of the screen:\nclip2.with_position((0.4,0.7), relative=True)\n\n# clip2's position is horizontally centered, and moving down!\nclip2.with_position(lambda t: ('center', 50+t) )\n</code></pre> <p>When indicating the position keep in mind that the <code>y</code> coordinate has its zero at the top of the picture:</p>"},{"location":"getting_started/mixing_clip/#compositing-audio-clips","title":"Compositing audio clips","text":"<p>When you mix video clips together, MoviePy will automatically compose their respective audio tracks to form the audio track of the final clip, so you don\u2019t need to worry about compositing these tracks yourself.</p> <p>If you want to make a custom audiotrack from several audio sources: audioc clips can be mixed together with CompositeAudioClip and concatenate_audioclips:</p> <pre><code>from moviepy import *\n# ... make some audio clips aclip1, aclip2, aclip3\nconcat = concatenate_audioclips([aclip1, aclip2, aclip3])\ncompo = CompositeAudioClip([aclip1.multiply_volume(1.2),\n                            aclip2.with_start(5), # start at t=5s\n                            aclip3.with_start(9)])\n</code></pre>"},{"location":"getting_started/quick_presentation/","title":"Getting started to use VidioPy","text":""},{"location":"getting_started/quick_presentation/#advantages-and-limitations","title":"Advantages and limitations","text":"<p>VidioPy has been developed with the following goals in mind:</p> <p>Advantages:</p> <ul> <li>Simple syntax for cutting, concatenations, title insertions, video compositing, video processing, and creation of custom effects.</li> <li>Same syntax for all operating systems (Linux, MacOX, Windows).</li> <li>Flexible : You have total control over the frames of the video and audio, and creating your own effects is easy as Py.</li> <li>Fast : you can batch operations as much as you want, backend in ffmpeg, pillow, numpy, etc. for speed.</li> <li>Supports most video formats and codecs. &amp; Question Support.</li> </ul> <p>limitations:</p> <ul> <li>still in development.</li> <li>less documentation &amp; Features.</li> </ul>"},{"location":"getting_started/quick_presentation/#how-vidiopy-works","title":"How Vidiopy works","text":"<p>Vidiopy Uses the ffmpeg (1) library to read and write video files. The processing of the different media is is proceed using modules like Numpy,  opencv, Pillow, ETC.</p> <ol> <li>ffmpeg is a tool for handling multimedia files. It is used for reading and writing video files, and for converting between   different video and audio formats.</li> </ol> <pre><code>flowchart LR\n    subgraph clips\n        video(film reel)\n        audio(sound wave)\n        pictures(image)\n    end\n    Processing[numpy, opencv, pillow, etc]\n    subgraph processing\n        Processing\n    end\n    subgraph output\n        Output_Image(Image Sequence, Image File)\n        Output_Video(Video File)\n        Output_Audio(Audio File)\n    end\n    video --&gt;|ffmpeg| processing\n    audio --&gt;|ffmpeg| processing\n    pictures --&gt;|ffmpeg or pillow| processing\n    processing --&gt;|ffmpeg| Output_Video\n    processing --&gt;|ffmpeg| Output_Audio\n    processing --&gt;|ffmpeg or pillow| Output_Image</code></pre>"},{"location":"getting_started/quick_presentation/#example-code","title":"Example code","text":"<pre><code>from vidiopy import VideoFileClip, TextClip\n\n# Load myHolidays.mp4 and trimming it to 10 seconds. 50s to 60s.\nclip = VideoFileClip(\"myHolidays.mp4\").subclip(50,60)\n\n# Generate a text clip. You can customize the font, color, etc.\ntxt_clip = TextClip(\"My Holidays 2013\", font_size=70, txt_color='white', bg_color='gray', font=r'path/to/font.ttf')\ntxt_clip = txt_clip.set_pos('center', 'right').set_duration(10)\n\n# Overlay the text clip on the first video clip\nvideo = CompositeVideoClip([clip, txt_clip])\n\n# Write the result to a video file in any format\nvideo.write_videofile(\"myHolidays_edited.webm\")\nvideo.write_videofile(\"myHolidays_edited.mp4\")\nvideo.write_videofile(\"myHolidays_edited.avi\")\nvideo.write_videofile(\"myHolidays_edited.mkv\")\n\n# Writing single frame\nvideo.save_frame(\"frame.png\", t=0.5) # t= time in seconds\n\n# Writing Image Sequence\nvideo.write_image_sequence(\"image%03d.png\", fps=24) # %03d are placeholders for the numbers 001, 002, 003, etc. fps = frames per second\nvideo.write_image_sequence(\"image%03d.jpg\", fps=24) # %03d are placeholders for the numbers 001, 002, 003, etc. fps = frames per second\nvideo.write_image_sequence(\"image%03d.bmp\", fps=24) # %03d are placeholders for the numbers 001, 002, 003, etc. fps = frames per second\n</code></pre>"},{"location":"getting_started/read%26write/","title":"Reading/Writing Video &amp; Audio","text":""},{"location":"getting_started/read%26write/#reading-video-from-file","title":"Reading Video from file","text":"<p>The first step of video editing is to reading them from file. this Van be Done using <code>vidiopy.VideoFileClip</code> class. This class takes the path of the video file as input and returns a video which inherits from <code>VideoClip</code> class.</p> <pre><code>import vidiopy\nvideo = vidiopy.VideoFileClip(\"path/to/video.extension\") # you can perform the operations on the video object\nvideo_without_audio = vidiopy.VideoFileClip(\"path/to/video.extension\", audio=False) # defaults to `audio=True`\n</code></pre> <p>if the video do not have the audio then it will create a silence clip</p>"},{"location":"getting_started/read%26write/#writing-video-to-file","title":"Writing Video to file","text":"<p>To Write the Video we can use the <code>write_videofile</code> function inside the <code>VideoClip</code>. Other clip type inherent it from the <code>VideoClip</code>.</p> <pre><code>import vidiopy\nvideo = vidiopy.VideoFileClip(\"path/to/video.extension\")\nvideo.write_videofile(\"path/to/output/video.extension\", fps=30) # fps is optional it will default use the fps of the video if it is set\n</code></pre>"},{"location":"getting_started/read%26write/#reading-audio-from-file","title":"Reading Audio from file","text":"<p>To read the audio from the file we can use the <code>AudioFileClip</code> class. This class takes the path of the audio file as input and returns a audio which inherits from <code>AudioClip</code> class.</p> <pre><code>import vidiopy\naudio = vidiopy.AudioFileClip(\"path/to/audio.extension\")\n</code></pre>"},{"location":"getting_started/read%26write/#writing-audio-to-file","title":"Writing Audio to file","text":"<p>To Write the Audio we can use the <code>write_audiofile</code> function inside the <code>AudioClip</code>. Other clip type inherent it from the <code>AudioClip</code>.</p> <pre><code>import vidiopy\naudio = vidiopy.AudioFileClip(\"path/to/audio.extension\")\naudio.write_audiofile(\"path/to/output/audio.extension\")\n</code></pre>"},{"location":"more/CONTRIBUTING/","title":"VidioPy's Contribution Guidelines","text":""},{"location":"more/CONTRIBUTING/#communication-on-github","title":"Communication on GitHub","text":"<ul> <li>Keep discussions on GitHub issues and pull requests focused and concise. Remember that each comment triggers a notification for multiple people.</li> <li>Before making significant changes to the core codebase, discuss them with the team.</li> </ul>"},{"location":"more/CONTRIBUTING/#setting-up-your-development-environment","title":"Setting Up Your Development Environment","text":"<ul> <li>Fork the official VidioPy repository to your own GitHub account.</li> <li>Clone the forked repository to your local machine.</li> <li>Create and activate a Python virtual environment to isolate the project dependencies.</li> <li>Navigate to the cloned directory and run <code>pip install -e .</code> to install the project dependencies.</li> <li>Regularly sync your local repository with the main repository to stay up-to-date with the latest changes.</li> </ul>"},{"location":"more/CONTRIBUTING/#coding-standards-and-code-quality","title":"Coding Standards and Code Quality","text":"<ul> <li>Adhere to the PEP8 coding conventions for Python.</li> <li>Use comments judiciously and only when necessary. Aim to write self-explanatory code.</li> <li>Choose clear and descriptive names for variables, functions, and classes.</li> <li>Document new features or bug fixes with docstring. Update the documentation in the <code>docs/markdown/</code> directory as needed.</li> <li>Use Prettier to maintain consistent code formatting.</li> <li>Review your code in PyCharm or VSCode to catch potential edge cases.</li> <li>When adding new functions or features, update the corresponding unit tests or mention the need for new tests in your pull request.</li> <li>read the Code Style Guide</li> </ul>"},{"location":"more/CONTRIBUTING/#submitting-pull-requests","title":"Submitting Pull Requests","text":"<ul> <li>You can submit a pull request (PR) even if your work is still in progress; it doesn't have to be fully finished.</li> <li>Before submitting your PR, run the test suite using pytest to ensure your changes haven't broken anything.</li> <li>Provide a clear and detailed description of your changes when submitting your PR. This will help the reviewers understand your work and expedite the review process.</li> </ul>"},{"location":"more/code%20style%20guide/","title":"code style guide","text":""},{"location":"more/code%20style%20guide/#functions-and-methods-docstrings","title":"functions and methods docstrings","text":""},{"location":"more/code%20style%20guide/#function-and-method-docstring-template","title":"function and method docstring template","text":"<pre><code>\"\"\"\\\nA Brief Description of the Function or Method\n\n#### Parameters:\n    - `param1` `type`: -\n        The first Doc.\n    - `param2` `type[type, type]`: -\n        The second Doc.\n    - `param3` `(type, optional, ...)`: -\n        The third Doc.\n    - `param4` `(type, optional, default=None)`: -\n        The fourth Doc.\n    - `*param5` `(type, optional, ...)`: -\n        The fifth Doc.\n    - `**param6` `(type, optional, ...)`: -\n        The sixth Doc.\n\n#### returns: # if return Multiple things\n    - `int`: - an a xyz.\n    - `float`: - an a abc\n\n#### return: `int` # if return Single thing\n    Doc goes here.\n\n#### return: `None` # if do not return anything\n\n#### raises: # add if needed\n    - `Error`: - if xyz.\n    - `Exception`: - if abc.\n\n#### Note: # add if needed\n    - xyz\n    - More notes.\n\n#### Warning: # add if needed\n    - xyz\n    - More warnings.\n\n#### examples:\n    example 1 :\n\n    \\`\\`\\`python\n    &gt;&gt;&gt; code\n    output\n    \\`\\`\\`\n    example 2 :\n\n    \\`\\`\\`python\n    code # explain\n    \\`\\`\\`\n    - More examples.\n\n#### TODO: # add if needed\n    - xyz\n    - More TODOs.\n\n#### [function reference manual](https://github.com/SohamTilekar/vidiopy/blob/master/docs/...)\n\n\"\"\"\n</code></pre>"},{"location":"more/code%20style%20guide/#function-and-method-docstring-conventions","title":"function and method docstring conventions","text":"<ul> <li>Docstrings are always triple quoted strings use <code>\"\"\"</code> not <code>'''</code>.</li> <li>add a blank line after the docstring.</li> <li>use the #### for the sections.</li> <li>add as much detail as possible.</li> <li>add the link to Function or Method Reference manuel.</li> </ul>"},{"location":"more/code%20style%20guide/#class-docstrings","title":"class docstrings","text":""},{"location":"more/code%20style%20guide/#class-docstring-template","title":"class docstring template","text":"<pre><code>\"\"\"\\\nA Brief Description of the Class\n\nproperties:\n    - `property1`: - a short 1 line description of the property.\n    - `property2`: - a short 1 line description of the property.\n\nmethods:\n    - `method1`: - a short 1 line description of the method.\n    - `method2`: - a short 1 line description of the method.\n\nabstract methods:\n    - `method1`: - a short 1 line description of the method.\n    - `method2`: - a short 1 line description of the method.\n\n#### Note: # add if needed\n    - xyz\n    - More notes.\n\n#### Warning: # add if needed\n    - xyz\n    - More warnings.\n\n#### examples:\n    example 1 :\n    \\`\\`\\`python\n    &gt;&gt;&gt; code\n    output\n    \\`\\`\\`\n\n    example 2 :\n    \\`\\`\\`python\n    code # explain\n    \\`\\`\\`\n    - More examples.\n\"\"\"\n</code></pre>"},{"location":"more/code%20style%20guide/#class-docstring-conventions","title":"class docstring conventions","text":"<ul> <li>Docstrings are always triple quoted strings use <code>\"\"\"</code> not <code>'''</code>.</li> <li>add a blank line after the docstring.</li> <li>use the #### for the sections.</li> <li>add as much detail as possible.</li> </ul>"},{"location":"more/code%20style%20guide/#comments","title":"Comments","text":"<ul> <li>Use as less comments as possible.</li> <li>Use comments where code is not self explanatory or weird.</li> </ul>"},{"location":"reference_manual/reference_manual/","title":"Reference Manual","text":"<ul> <li> <p>Clip</p> </li> <li> <p>VideoClips</p> <ul> <li>VideoClip</li> <li>VideoFileClip</li> <li>ImageClips</li> <li>ImageSequenceClip</li> <li>Mixing Clip</li> </ul> </li> <li> <p>Audioclips</p> <ul> <li>AudioClip</li> <li>AudioFileClip</li> <li>AudioArrayClip</li> <li>SilenceClip</li> <li>Mixing Audio</li> </ul> </li> </ul>"},{"location":"reference_manual/clips/clip/","title":"Clip","text":"<p><code>class</code> <code>vidiopy.Clip.Clip</code></p> <p>Bases: <code>object</code></p> <p>A Clip is the base class for all the clips (<code>VideoClip</code> and <code>AudioClip</code>).</p> <p><code>fx(func, *args, **kwargs)</code></p> <p>Apply a function to the current instance and return the result.</p> <p>This method allows for the application of any callable to the current instance of the class. The callable should take the instance as its first argument, followed by any number of positional and keyword arguments.</p> Parameters: <ul> <li><code>func: (Callable[..., Self])</code>: The function to apply. This should take the instance as its first argument.</li> <li><code>*args</code>: Variable length argument list for the function.</li> <li><code>**kwargs</code>: Arbitrary keyword arguments for the function.</li> </ul> Returns: <ul> <li><code>Self</code>: The result of applying the function to the instance.</li> </ul> Example: <pre><code>&gt;&gt;&gt; clip = Clip()\n&gt;&gt;&gt; def do(instance):\n...     # Do something with instance.\n...     return instance.\n...\n&gt;&gt;&gt; new_clip = clip.fx(do)\n</code></pre> <p><code>copy()</code></p> <p>Creates a deep copy of the current Clip object.</p> <p>This method creates a new instance of the Clip object, copying all the attributes of the current object into the new one. If the current object has an 'audio' attribute, it also creates a deep copy of this 'audio' object and assigns it to the 'audio' attribute of the new Clip object.</p> Returns: <code>Clip</code>: A new Clip object that is a deep copy of the current object. <p><code>close()</code></p> Release any resources that are in use. <p><code>__enter__()</code></p> Enter the context manager. <p><code>__exit__()</code></p> Exit the context manager."},{"location":"reference_manual/clips/audio_clips/audioarrayclip/","title":"AudioArrayClip","text":"<p><code>class</code> <code>vidiopy.AudioArrayClip</code></p> <p>Bases: <code>vidiopy.AudioClip</code></p> <p>AudioArrayClip is a class that represents an audio clip from an array. It extends the AudioClip class.</p> Parameters: <ul> <li><code>audio_data: np.ndarray</code>: The audio data.</li> <li><code>fps: int</code>: The sample rate of the audio clip.</li> <li><code>duration: int | float</code>: The duration of the audio clip.</li> </ul> Example: <p>```python import numpy as np import vidiopy</p> <p>audio_data = np.random.uniform(-1, 1, 44100 * 3) # 3 seconds of random audio audio_clip = vidiopy.AudioArrayClip(audio_data, fps=44100) ```</p>"},{"location":"reference_manual/clips/audio_clips/audioclip/","title":"AudioClip","text":"<p><code>class</code> <code>vidiopy.AudioClip</code></p> <p>Bases: <code>vidiopy.Clip</code></p> <p>The AudioClip class represents an audio clip. It is a subclass of the Clip class.</p> Parameters: <ul> <li><code>duration (int or float, optional)</code>: The duration of the audio clip. Defaults to <code>None</code>.</li> <li><code>fps (int, optional)</code>: Frames per second of the audio clip. Defaults to <code>None</code>.</li> </ul> Attributes: <ul> <li><code>fps: int | None</code>: The frames per second of the audio clip. Defaults to <code>fps</code> Parameter.</li> <li><code>_original_dur: int | float | None</code>: The original duration of the audio clip. Defaults to <code>duration</code> Parameter.</li> <li><code>_audio_data: np.ndarray | None</code>: The audio data of the clip. Defaults to <code>None</code>.</li> <li><code>channels: int | None</code>: The number of audio channels. Defaults to <code>None</code>.</li> <li><code>_st: int | float</code>: The start time of the audio clip. Defaults to <code>0.0</code>.</li> <li><code>_ed: int | float | None</code>: The end time of the audio clip. Defaults to <code>duration</code> Parameter.</li> </ul> Properties: <p><code>audio_data: np.ndarray</code></p> <p>This property gets the audio data. If the audio data is not set, it <code>raises</code> a <code>ValueError</code>.</p> Returns: <code>np.ndarray</code>: The audio data. Raises: <code>ValueError</code>: If the audio data is not set. <p>Example: :     <pre><code>&gt;&gt;&gt; clip = AudioClip()\n&gt;&gt;&gt; clip.audio_data = np.array([1, 2, 3])\n&gt;&gt;&gt; print(clip.audio_data)\narray([1, 2, 3])\n</code></pre></p> <p><code>duration: int | float</code></p> <p>This property gets the duration of the audio clip. The duration is represented in seconds and can be an <code>integer</code>, a <code>float</code>, or <code>None</code> if the duration is not set.</p> Note: You Can't Set the duration of the audio clip it is not allowed to change directly. <p>Raises:     <code>AttributeError</code>: Always raises an <code>AttributeError</code> if you try to set duration.</p> Returns: <code>int | float</code>: The duration of the audio clip. <p>Example: :     <pre><code>&gt;&gt;&gt; clip = AudioClip(duration=10)\n&gt;&gt;&gt; print(clip.duration)\n10\n</code></pre></p> <p><code>start: int | float</code></p> <p>This property gets the start time of the audio clip. The start time is represented in seconds and can be an <code>integer</code> or a <code>float</code>.</p> Returns: <code>int | float</code>: The start time of the audio clip. <p>Example: :     <pre><code>&gt;&gt;&gt; clip = AudioClip()\n&gt;&gt;&gt; print(clip.start)\n0.0\n&gt;&gt;&gt; clip.start = 5\n&gt;&gt;&gt; print(clip.start)\n5\n</code></pre></p> <p><code>end: int | float | None</code></p> <p>This property gets the end time of the audio clip. The end time is represented in seconds and can be an <code>integer</code>, a <code>float</code>, or <code>None</code> if the end time is not set.</p> Returns: <code>int | float | None</code>: The end time of the audio clip. <p>Example: :     <pre><code>&gt;&gt;&gt; clip = AudioClip(duration=10)\n&gt;&gt;&gt; print(clip.end)\n10\n&gt;&gt;&gt; clip.end = 5\n&gt;&gt;&gt; print(clip.end)\n5\n</code></pre></p> Methods: <p><code>def</code> <code>set_data(self, audio_data: np.ndarray) -&gt; Self</code>:</p> <p>This method sets the audio data and returns the instance of the class.</p> Args: audio_data (np.ndarray): The audio data to set. Returns: AudioClip: The instance of the class. <p>Example: :     <pre><code>    &gt;&gt;&gt; clip = AudioClip()\n    &gt;&gt;&gt; clip.set_data(np.array([1, 2, 3]))\n    &gt;&gt;&gt; print(clip.audio_data)\n    array([1, 2, 3])\n</code></pre></p> <p><code>def</code> <code>set_fps(self, fps: int | None) -&gt; Self</code>:</p> <p>This method sets the frames per second (fps) for the audio clip and <code>returns</code> the instance of the <code>class</code>.</p> Args: <code>fps: int | None</code>: The frames per second to set. If <code>None</code>, the fps will be unset. Returns: <code>AudioClip</code>: <code>Self</code> The Instance of the <code>class</code>. <p>Example: :     <pre><code>&gt;&gt;&gt; clip = AudioClip()\n&gt;&gt;&gt; clip.set_fps(30)\n&gt;&gt;&gt; print(clip.fps)\n30\n</code></pre></p> <p><code>def</code> <code>set_start(self, start: int | float) -&gt; Self</code>:</p> <p>This method sets the start time of the audio clip and returns the instance of the class. The start time is represented in seconds and can be an <code>integer</code> or a <code>float</code>.</p> Args: <code>start: int | float</code>: The start time to set in seconds. Returns: <code>AudioClip</code>: The instance of the class with the updated start time. <p>Example: :     <pre><code>&gt;&gt;&gt; clip = AudioClip()\n&gt;&gt;&gt; clip.set_start(5)\n&gt;&gt;&gt; print(clip.start)\n5\n</code></pre></p> <p><code>def</code> <code>set_end(self, end: int | float | None) -&gt; Self</code>:</p> <p>This method sets the end time of the audio clip and returns the instance of the class. The end time is represented in seconds and can be an <code>integer</code>, a <code>float</code>, or <code>None</code> if the end time is not to be set.</p> Args: <code>end: int | float | None</code>: The end time to set in seconds. Returns: <code>AudioClip</code>: The instance of the class with the updated end time. <p>Example: :     <pre><code>&gt;&gt;&gt; clip = AudioClip()\n&gt;&gt;&gt; clip.set_end(10)\n&gt;&gt;&gt; print(clip.end)\n10\n</code></pre></p> <p><code>def</code> <code>get_frame_at_t(self, t: int | float) -&gt; np.ndarray</code>:</p> <p>This method gets the audio frame at a specific time <code>t</code>. The time <code>t</code> is represented in seconds and can be an <code>integer</code> or a <code>float</code>. It calculates the frame index using the duration, total frames, and time <code>t</code>, and returns the audio data at that frame index.</p> Args: <code>t: int | float</code>: The time in seconds at which to get the audio frame. Returns: <code>np.ndarray</code>: The audio data at the specified time. Raises: <code>ValueError</code>: If frames per second (fps) is not set, audio data is not set, or original duration is not set. <p><code>def</code> <code>iterate_frames_at_fps(self, fps: int | float | None = None) -&gt; Generator[np.ndarray, None, None]:</code></p> <p>This method generates audio frames at a specific frames per second (fps) rate. If no fps is provided, it uses the fps set in the AudioClip instance. It calculates the original fps using the duration and total frames, then generates frames at the specified fps rate.</p> Args: <code>fps (int | float | None, optional)</code>: The frames per second rate at which to generate frames. If not provided, the fps set in the AudioClip instance is used. Yields: <code>np.ndarray</code>: The audio data at each frame. Raises: <code>ValueError</code>: If frames per second (fps) is not set, audio data is not set, or original duration is not set. <p><code>def</code> <code>iterate_all_frames(self) -&gt; Generator[np.ndarray, None, None]:</code></p> <p>This method generates all audio frames in the <code>AudioClip</code> instance. It iterates over each frame in the audio data and <code>yields</code> it.</p> Yields: <code>np.ndarray</code>: The audio data at each frame. Raises: <code>ValueError</code>: If audio data is not set. <p><code>def</code> <code>fl_frame_transform(self, func, *args, **kwargs) -&gt; Self:</code></p> <p>This method applies a function to each frame of the audio data. The function should take a frame (an ndarray of channel data) as its first argument, followed by any number of additional positional and keyword arguments.</p> Args: <ul> <li><code>func (Callable)</code>: The function to apply to each frame. It should take a frame (an ndarray of channel data) as its first argument.</li> <li><code>*args</code>: Additional positional arguments to pass to the function.</li> <li><code>**kwargs</code>: Additional keyword arguments to pass to the function.</li> </ul> Returns: <code>AudioClip</code>: The instance of the class with the transformed audio data. Raises: <code>ValueError</code>: If audio data is not set. <p><code>def</code> <code>fl_clip_transform(self, func, *args, **kwargs) -&gt; Self:</code></p> <p>This method applies a function to the entire audio data. The function should take the AudioClip instance as its first argument, followed by any number of additional positional and keyword arguments.</p> Args: <ul> <li><code>func (Callable)</code>: The function to apply to the audio data. It should take the AudioClip instance as its first argument.</li> <li><code>*args</code>: Additional positional arguments to pass to the function.</li> <li><code>**kwargs</code>: Additional keyword arguments to pass to the function.</li> </ul> Returns: <code>AudioClip</code>: The instance of the class with the transformed audio data. Raises: <code>ValueError</code>: If audio data is not set. <p><code>def</code> <code>fl_time_transform(self, func: Callable[[int | float], int | float]) -&gt; Self:</code></p> <p>This method applies a time transformation function to the <code>get_frame_at_t</code> method of the AudioClip instance. The transformation function should take a time (an integer or a float) as its argument and return a transformed time.</p> <p>The <code>get_frame_at_t</code> method is replaced with a new method that applies the transformation function to its argument before calling the original method.</p> Args: <code>func (Callable[[int | float], int | float])</code>: The time transformation function to apply. It should take a time (an integer or a float) as its argument and return a transformed time. Returns: <code>AudioClip</code>: The instance of the class with the transformed <code>get_frame_at_t</code> method. Raises: <code>ValueError</code>: If the <code>get_frame_at_t</code> method is not set. <p><code>def</code> <code>sub_clip_copy(self, start: float | int | None = None, end: float | int | None = None) -&gt; Self</code></p> <p>This method creates a copy of the AudioClip instance and then creates a subclip from the audio clip starting from <code>start</code> to <code>end</code> in the copied instance. If <code>start</code> or <code>end</code> is not provided, it uses the start or end time set in the AudioClip instance. If neither is set, it uses 0 for start and the duration for end.</p> <p>It calculates the original frames per second (fps) using the duration and total frames, then calculates the start and end frame indices using the original fps. It then updates the audio data, original duration, end time, and start time of the copied AudioClip instance.</p> Args: <ul> <li><code>start (float | int | None, optional)</code>: The start time of the subclip in seconds. If not provided, the start time set in the AudioClip instance is used. Defaults to <code>None</code>.</li> <li><code>end (float | int | None, optional)</code>: The end time of the subclip in seconds. If not provided, the end time set in the AudioClip instance is used. Defaults to <code>None</code>.</li> </ul> Returns: <code>AudioClip</code>: A copy of the instance of the class with the updated audio data, original duration, end time, and start time. Raises: <code>ValueError</code>: If audio data is not set, original duration is not set, or end time is greater than the original duration. <p><code>def</code> <code>copy(self) -&gt; Self</code>:</p> This method creates a deep copy of the AudioClip instance and returns it. It uses the <code>copy_</code> function, which should be a deep copy function like <code>copy.deepcopy</code> in Python's standard library. Returns: <code>AudioClip</code>: A deep copy of the instance of the class. Raises: <code>ValueError</code>: If the <code>copy_</code> function is not set or does not correctly create a deep copy. &gt; <code>def</code> <code>write_audiofile(self, path: str, fps: int | None = None, overwrite=True, show_log=False, **kwargs) -&gt; None:</code> <p>This method writes the audio data to an audio file at the specified path. It uses the frames per second (fps) if provided, otherwise it uses the fps set in the <code>AudioClip</code> instance. It raises a <code>ValueError</code> if fps is not set in either way. It also raises a <code>ValueError</code> if audio data, original duration, or channels are not set.</p> <p>It creates a temporary audio data array by getting the frame at each time step from <code>0</code> to the end or duration with a step of <code>1/fps</code>. It then writes the temporary audio data to the audio file using the <code>ffmpegio.audio.write</code> function.</p> Args: <ul> <li>path (str): The path to write the audio file to.</li> <li>fps (int | None, optional): The frames per second to use. If not provided, the fps set in the AudioClip instance is used. Defaults to None.</li> <li>overwrite (bool, optional): Whether to overwrite the audio file if it already exists. Defaults to True.</li> <li>show_log (bool, optional): Whether to show the log of the <code>ffmpegio.audio.write</code> function. Defaults to False.</li> <li>**kwargs: Additional keyword arguments to pass to the <code>ffmpegio.audio.write</code> function.</li> </ul> Raises: <code>ValueError</code>: If fps is not set, audio data is not set, original duration is not set, or channels are not set."},{"location":"reference_manual/clips/audio_clips/audiofileclip/","title":"AudioFileClip","text":"<p><code>class</code> <code>vidiopy.AudioFileClip</code></p> <p>Bases: <code>vidiopy.SilenceClip</code></p> <p>AudioFileClip is a class that represents an audio file. It extends the SilenceClip class.</p> Parameters: <ul> <li><code>path: str | pathlib.Path</code>: The path to the audio file.</li> <li><code>duration (int | float | None, optional)</code>: The duration of the audio file. If not provided, it will be calculated from the audio file.</li> </ul> Raises: <ul> <li><code>ValueError</code>: If the audio file is empty and duration is not provided.</li> </ul>"},{"location":"reference_manual/clips/audio_clips/mixingaudio/","title":"Concatenating Audio Clips","text":"<p><code>def</code> <code>concatenate_audioclips(clips: list[AudioClip], fps: int | None = 44100) -&gt; AudioClip | AudioArrayClip:</code></p> <p>Concatenates multiple audio clips into a single audio clip.</p> Parameters: <ul> <li><code>clips: list[AudioClip]</code>: A list of AudioClip objects to be concatenated.</li> <li><code>fps (int, optional)</code>: The frames per second (fps) for the output AudioClip. If not provided, it defaults to 44100, or the maximum fps value found in the input clips.</li> </ul> Returns: <p><code>AudioClip | AudioArrayClip</code>: The concatenated AudioClip. If the input clips have different channels, the output <code>AudioClip</code> will have the maximum number of channels found in the input clips, and the missing channels in the other clips will be filled with the mean value of their existing channels.</p> Raises: <p><code>ValueError</code>: If no clips are provided, or if no fps value is found or set, or if a clip's channels are not set.</p> Note: <ul> <li>The duration of the output <code>AudioClip</code> is the sum of the durations of the input clips.</li> <li>If a clip's end time is set, it is used to calculate its duration; otherwise, its duration attribute is used.</li> <li>If neither is set, a <code>ValueError</code> is <code>raised</code>.</li> </ul>"},{"location":"reference_manual/clips/audio_clips/mixingaudio/#compositing-audio-clips","title":"Compositing Audio Clips","text":"<p><code>def</code> <code>composite_audioclips(clips: list[AudioClip], fps: int | None = 44100, use_bg_audio: bool = False) -&gt; AudioArrayClip:</code></p> <p>Composites multiple audio clips into a single audio clip.</p> Parameters: <ul> <li><code>clips: list[AudioClip]</code>: A list of AudioClip objects to be composited.</li> <li><code>fps (int, optional)</code>: The frames per second (fps) for the output AudioClip. If not provided, it defaults to the maximum fps value found in the input clips.</li> <li><code>use_bg_audio (bool, optional)</code>: If True, the first clip in the list is used as the background audio. The remaining clips are overlaid on top of this background audio. If False, a SilenceClip of the maximum duration found in the clips is used as the background audio.</li> </ul> Returns: <p><code>AudioArrayClip</code>: The composited AudioClip. The output AudioClip will have the maximum number of channels found in the input clips, and the missing channels in the other clips will be filled with the mean value of their existing channels.</p> Raises: <p><code>ValueError</code>: If no clips are provided, or if no fps value is found or set, or if a clip's channels are not set, or if no duration is found or set in the clips when use_bg_audio is False.</p> Note: <ul> <li>The duration of the output <code>AudioClip</code> is the duration of the background audio.</li> <li>If a clip's end time is set, it is used to calculate its duration; otherwise, its duration attribute is used.</li> <li>If neither is set, a <code>ValueError</code> is <code>raised</code>.</li> </ul>"},{"location":"reference_manual/clips/audio_clips/silenceclip/","title":"Silence Clip","text":"<p><code>class</code> <code>vidiopy.SilenceClip</code></p> <p>Bases: <code>vidiopy.AudioClip</code></p> <p>SilenceClip is a subclass of AudioClip that represents a silent audio clip.</p> <p>It inherits from AudioClip therefore it has all the methods and attributes of AudioClip.</p> Parameters: <ul> <li><code>duration: int | float</code>: The duration of the audio clip.</li> <li><code>fps (int, optional)</code>: The frames per second of the audio clip. Default is <code>44100</code>.</li> <li><code>channels (int, optional)</code>: The number of audio channels. Default is <code>1</code>.</li> </ul>"},{"location":"reference_manual/clips/video_clips/imageclips/","title":"ImageClip","text":"<p><code>class</code> <code>vidiopy.ImageClip(image: str | Path | Image.Image | np.ndarray | None = None, fps: int | float | None = None, duration: int | float | None = None)</code></p> <p>Bases: <code>vidiopy.VideoClip</code></p> <p>All Methods and properties of the <code>VideoClip</code> <code>class</code> are available.</p> <p>A <code>class</code> representing a video clip generated from a single image.</p> Parameters: <ul> <li><code>image: str | Path | Image.Image | np.ndarray | None</code>: The image to use for the video clip. If <code>None</code>, an empty video clip is created.</li> <li><code>fps: int | float | None</code>: The frames per second of the video clip. If <code>None</code>, the fps is set to 30.</li> <li><code>duration: int | float | None</code>: The duration of the video clip in seconds. If <code>None</code>, the duration is set to 1.</li> </ul> Attributes: <ul> <li><code>image: Image.Image</code>: The image used for the video clip.</li> <li>Other attributes are inherited from the <code>VideoClip</code> <code>class</code>.</li> </ul> Methods: <p><code>_import_image(self, image) -&gt; Image.Image</code>:</p> <p>Import the image from various sources.</p> <p>Does not made for external use.</p> Parameters: <code>image (str | Path | Image.Image | np.ndarray)</code>: Input image data. Returns: <code>Image.Image</code>: The imported image data. <p>This is a private method and not intended for external use.</p> <p>You Can Use <code>set_duration()</code> &amp; duration property to change _dur.</p> <p><code>fl_frame_transform(self, func, *args, **kwargs) -&gt; Self</code>:</p> <p>Apply a frame transformation function to the image.</p> Parameters: <code>func (Callable)</code>: The frame transformation function. <code>*args</code>: Additional positional arguments for the function. <code>**kwargs</code>: Additional keyword arguments for the function. Returns: <code>ImageClip</code>: A new ImageClip instance with the transformed image. Note: This method modifies the current ImageClip instance in-place. Example Usage: <pre><code>image_clip = ImageClip(image_path, fps=30, duration=5.0)\ntransformed_clip = image_clip.fl_frame_transform(resize, width=640, height=480)\n</code></pre> <p><code>fl_frame_transform(self, func, *args, **kwargs) -&gt; Self</code>:</p> <p>Apply a frame transformation function to the image.</p> Parameters: <code>func (Callable)</code>: The frame transformation function. <code>*args</code>: Additional positional arguments for the function. <code>**kwargs</code>: Additional keyword arguments for the function. Returns: <code>ImageClip</code>: A new ImageClip instance with the transformed image. Note: This method modifies the current ImageClip instance in-place. Example Usage: <pre><code>image_clip = ImageClip(image_path, fps=30, duration=5.0)\ntransformed_clip = image_clip.fl_frame_transform(resize, width=640, height=480)\n</code></pre> <p><code>fl_clip_transform(self, func, *args, **kwargs) -&gt; Self</code>:</p> <p>Raise a ValueError indicating that fl_clip is not applicable for ImageClip.</p> <p>The Clip should be converted to VideoClip using <code>to_video_clip</code> method first.</p> Parameters: <code>func</code>: Unused. <code>*args</code>: Unused. <code>**kwargs</code>: Unused. Returns: <code>ImageClip</code>: The current ImageClip instance. Raises: <code>ValueError</code>: This method is not applicable for ImageClip. Example Usage: <pre><code>image_clip = ImageClip(image_path, fps=30, duration=5.0)\nimage_clip.fl_clip(some_function)  # Raises ValueError\n</code></pre> <p><code>fx(self, func: Callable, *args, **kwargs)</code>:</p> <p>Apply a generic function to the ImageClip.</p> Parameters: <code>func (Callable)</code>: The function to apply. <code>*args</code>: Additional positional arguments for the function. <code>**kwargs</code>: Additional keyword arguments for the function. Returns: <code>ImageClip</code>: The current ImageClip instance. Note: This method modifies the current ImageClip instance in-place. Example Usage: <pre><code>def custom_function(image):\n    # Some custom processing on the image\n    return modified_image\n\nimage_clip = ImageClip(image_path, fps=30, duration=5.0)\nimage_clip.fx(custom_function, some_arg=42)\n</code></pre> <p><code>sub_fx(self, func, *args, start_t: int | float | None = None, end_t: int | float | None = None, **kwargs) -&gt; Self</code>:</p> <p>Apply a custom function to the Image Clip.</p> Note: Before using the <code>sub_fx</code> method, you need to convert the image clip to a video clip using <code>to_video_clip()</code> function. Args: <code>func</code>: The custom function to apply to the Image Clip. <code>*args</code>: Additional positional arguments to pass to the custom function. <code>start_t (int | float | None)</code>: The start time of the subclip in seconds. If None, the subclip starts from the beginning. <code>end_t (int | float | None)</code>: The end time of the subclip in seconds. If None, the subclip ends at the last frame. <code>**kwargs</code>: Additional keyword arguments to pass to the custom function. Returns: <code>Self</code>: The modified ImageClips instance. Example: <pre><code># Convert the image clip to a video clip\nvideo_clip = image_clip.to_video_clip()\n\n# Apply a custom function to the video clip\nmodified_clip = video_clip.sub_fx(custom_function, start_t=2, end_t=5)\n</code></pre> Raises: <code>ValueError</code>: If the method is called on an Image Clip instead of a Video Clip. <p><code>sub_clip_copy(self, start: int | float | None = None, end: int | float | None = None) -&gt; Self</code>:</p> <p>Create a copy of the current clip and apply sub-clip operation. Read more about sub-clip operation in the <code>sub_clip</code> method.</p> Args: <code>start (int | float | None)</code>: Start time of the sub-clip in seconds. If None, the sub-clip starts from the beginning of the original clip. <code>end (int | float | None)</code>: End time of the sub-clip in seconds. If None, the sub-clip ends at the end of the original clip. Returns: <code>Self</code>: A new instance of the clip with the sub-clip applied. Example: <pre><code>image_clip = ImageClip(image_path, fps=30, duration=5.0)\nsub_clip = image_clip.sub_clip_copy(start=2, end=5)\n</code></pre> <p><code>sub_clip(self, start: int | float | None = None, end: int | float | None = None) -&gt; Self</code>:</p> <p>Returns a sub-clip of the current clip.</p> Args: <code>start (int | float | None, optional)</code>: The start time of the sub-clip in seconds. Defaults to None. <code>end (int | float | None, optional)</code>: The end time of the sub-clip in seconds. Defaults to None. Returns: <code>Self</code>: The sub-clip. Note: It modifies the current clip in-place. If both <code>start</code> and <code>end</code> are None, the original clip is returned. If <code>start</code> is None, it defaults to 0. If <code>end</code> is None, it defaults to the end time of the original clip. Example: <pre><code>image_clip = ImageClip(image_path, fps=30, duration=5.0)\nimage_clip.sub_clip(start=2, end=5)\n</code></pre> <p><code>make_frame_array(self, t)</code>:</p> <p>Gives the numpy array representation of the image at a given time.</p> Args: <code>t (float)</code>: The timestamp of the frame. Returns: <code>numpy.ndarray</code>: The numpy array representation of the image. Raises: <code>ValueError</code>: If the image is not set. <p><code>make_frame_pil(self, t) -&gt; Image.Image</code>:</p> <p>Returns the image frame at a given time.</p> Args: <code>t (float)</code>: The time at which to retrieve the frame. Returns: <code>PIL.Image.Image</code>: The image frame at the given time. Raises: <code>ValueError</code>: If the image is not set. <p><code>to_video_clip(self, fps=None, duration=None)</code>:</p> <p>Convert <code>ImageClip</code> to <code>VideoClip</code></p> <p>If fps or duration is not provided, it defaults to the corresponding attribute of the ImageClip instance. If those attributes are not available, a ValueError is raised.</p> Parameters: <code>fps (float, optional)</code>: Frames per second of the resulting video clip. If not provided, it defaults to the fps attribute of the ImageClip instance. If that is also not available, a ValueError is raised. <code>duration (float, optional)</code>: Duration of the resulting video clip in seconds. If not provided, it defaults to the duration attribute of the ImageClip instance. If that is also not available, a ValueError is raised. Returns: <code>ImageSequenceClip</code>: A VideoClip subclass instance generated from the ImageClip frames. Raises: <code>ValueError</code>: If fps or duration is not provided and the corresponding attribute is not available. Note: The <code>to_video_clip</code> method returns an instance of the <code>ImageSequenceClip</code> class, which is a subclass of the <code>VideoClip</code> Class. Example Usage: <pre><code># Example Usage\nimage_clip = ImageClip()\nvideo_clip = image_clip.to_video_clip(fps=24, duration=10.0)\nvideo_clip.sub_fx(custom_function, start_t=2, end_t=5)\n</code></pre>"},{"location":"reference_manual/clips/video_clips/imageclips/#data2imageclip","title":"Data2ImageClip","text":"<p><code>class</code> <code>vidiopy.Data2ImageClip(data: np.ndarray | Image.Image, fps: int | float | None = None, duration: int | float | None = None)</code></p> <p>Bases: <code>vidiopy.ImageClip</code></p> <p>A class representing a video clip generated from raw data (numpy array or PIL Image).</p> <p>It extends the <code>ImageClip</code> class and allows users to create video clips from raw data, supporting either numpy arrays or PIL Images as input.</p> Parameters: <ul> <li><code>data (np.ndarray or PIL Image)</code>: The raw data to be converted into a video clip.</li> <li><code>fps (int | float | None)</code>: Frames per second of the video. If not provided, it will be inherited from the parent class (ImageClip) or set to the default value.</li> <li><code>duration (int | float | None)</code>: Duration of the video in seconds. If not provided, it will be inherited from the parent class (ImageClip) or set to the default value.</li> </ul> Attributes: <ul> <li><code>image (PIL Image)</code>: The PIL Image representation of the provided data.</li> <li><code>size (tuple)</code>: The size (width, height) of the image.</li> </ul> Methods: <p><code>_import_image(self, image) -&gt; Image.Image</code>:</p> <p>Private method to convert the provided data (numpy array or PIL Image) into a PIL Image.</p> Parameters: <code>image (np.ndarray or PIL Image)</code>: The raw data to be converted. Returns: <code>Image.Image</code>: The PIL Image representation of the provided data. Raises: <code>TypeError</code>: If the input type is not supported (neither numpy array nor PIL Image). Example Usage: <pre><code># Import necessary libraries\n\n# Create a Data2ImageClip instance from a numpy array\ndata_array = np.random.randint(0, 255, size=(480, 640, 3), dtype=np.uint8)\nvideo_clip = Data2ImageClip(data=data_array, fps=30, duration=5)\n\n# Create a Data2ImageClip instance from a PIL Image\nfrom PIL import Image\ndata_image = Image.new('RGB', (640, 480), color='red')\nvideo_clip = Data2ImageClip(data=data_image, fps=24, duration=10)\n</code></pre> Note: <p>The <code>Data2ImageClip</code> class extends the <code>ImageClip</code>. It allows users to create video clips from raw data, supporting either numpy arrays or PIL Images as input.</p>"},{"location":"reference_manual/clips/video_clips/imageclips/#colorclip","title":"ColorClip","text":"<p><code>class</code> <code>vidiopy.ColorClip(color: str | tuple[int, ...], mode=\"RGBA\", size=(1, 1), fps=None, duration=None)</code></p> <p>Bases: #!py vidiopy.Data2ImageClip</p> <p>A video clip class with a solid color.</p> <p>It extends the <code>Data2ImageClip</code> class and allows users to create video clips with a solid color.</p> Parameters: <ul> <li> <p><code>color: str | tuple[int, ...]</code>: Color of the image. It can be a color name (e.g., 'red', 'blue') or RGB tuple.</p> Available Color Names <ul> <li> <code>aliceblue: \"#f0f8ff\"</code>,</li> <li> <code>antiquewhite: \"#faebd7\"</code>,</li> <li> <code>aqua: \"#00ffff\"</code>,</li> <li> <code>aquamarine: \"#7fffd4\"</code>,</li> <li> <code>azure: \"#f0ffff\"</code>,</li> <li> <code>beige: \"#f5f5dc\"</code>,</li> <li> <code>bisque: \"#ffe4c4\"</code>,</li> <li> <code>black: \"#000000\"</code>,</li> <li> <code>blanchedalmond: \"#ffebcd\"</code>,</li> <li> <code>blue: \"#0000ff\"</code>,</li> <li> <code>blueviolet: \"#8a2be2\"</code>,</li> <li> <code>brown: \"#a52a2a\"</code>,</li> <li> <code>burlywood: \"#deb887\"</code>,</li> <li> <code>cadetblue: \"#5f9ea0\"</code>,</li> <li> <code>chartreuse: \"#7fff00\"</code>,</li> <li> <code>chocolate: \"#d2691e\"</code>,</li> <li> <code>coral: \"#ff7f50\"</code>,</li> <li> <code>cornflowerblue: \"#6495ed\"</code>,</li> <li> <code>cornsilk: \"#fff8dc\"</code>,</li> <li> <code>crimson: \"#dc143c\"</code>,</li> <li> <code>cyan: \"#00ffff\"</code>,</li> <li> <code>darkblue: \"#00008b\"</code>,</li> <li> <code>darkcyan: \"#008b8b\"</code>,</li> <li> <code>darkgoldenrod: \"#b8860b\"</code>,</li> <li> <code>darkgray: \"#a9a9a9\"</code>,</li> <li> <code>darkgrey: \"#a9a9a9\"</code>,</li> <li> <code>darkgreen: \"#006400\"</code>,</li> <li> <code>darkkhaki: \"#bdb76b\"</code>,</li> <li> <code>darkmagenta: \"#8b008b\"</code>,</li> <li> <code>darkolivegreen: \"#556b2f\"</code>,</li> <li> <code>darkorange: \"#ff8c00\"</code>,</li> <li> <code>darkorchid: \"#9932cc\"</code>,</li> <li> <code>darkred: \"#8b0000\"</code>,</li> <li> <code>darksalmon: \"#e9967a\"</code>,</li> <li> <code>darkseagreen: \"#8fbc8f\"</code>,</li> <li> <code>darkslateblue: \"#483d8b\"</code>,</li> <li> <code>darkslategray: \"#2f4f4f\"</code>,</li> <li> <code>darkslategrey: \"#2f4f4f\"</code>,</li> <li> <code>darkturquoise: \"#00ced1\"</code>,</li> <li> <code>darkviolet: \"#9400d3\"</code>,</li> <li> <code>deeppink: \"#ff1493\"</code>,</li> <li> <code>deepskyblue: \"#00bfff\"</code>,</li> <li> <code>dimgray: \"#696969\"</code>,</li> <li> <code>dimgrey: \"#696969\"</code>,</li> <li> <code>dodgerblue: \"#1e90ff\"</code>,</li> <li> <code>firebrick: \"#b22222\"</code>,</li> <li> <code>floralwhite: \"#fffaf0\"</code>,</li> <li> <code>forestgreen: \"#228b22\"</code>,</li> <li> <code>fuchsia: \"#ff00ff\"</code>,</li> <li> <code>gainsboro: \"#dcdcdc\"</code>,</li> <li> <code>ghostwhite: \"#f8f8ff\"</code>,</li> <li> <code>gold: \"#ffd700\"</code>,</li> <li> <code>goldenrod: \"#daa520\"</code>,</li> <li> <code>gray: \"#808080\"</code>,</li> <li> <code>grey: \"#808080\"</code>,</li> <li> <code>green: \"#008000\"</code>,</li> <li> <code>greenyellow: \"#adff2f\"</code>,</li> <li> <code>honeydew: \"#f0fff0\"</code>,</li> <li> <code>hotpink: \"#ff69b4\"</code>,</li> <li> <code>indianred: \"#cd5c5c\"</code>,</li> <li> <code>indigo: \"#4b0082\"</code>,</li> <li> <code>ivory: \"#fffff0\"</code>,</li> <li> <code>khaki: \"#f0e68c\"</code>,</li> <li> <code>lavender: \"#e6e6fa\"</code>,</li> <li> <code>lavenderblush: \"#fff0f5\"</code>,</li> <li> <code>lawngreen: \"#7cfc00\"</code>,</li> <li> <code>lemonchiffon: \"#fffacd\"</code>,</li> <li> <code>lightblue: \"#add8e6\"</code>,</li> <li> <code>lightcoral: \"#f08080\"</code>,</li> <li> <code>lightcyan: \"#e0ffff\"</code>,</li> <li> <code>lightgoldenrodyellow: \"#fafad2\"</code>,</li> <li> <code>lightgreen: \"#90ee90\"</code>,</li> <li> <code>lightgray: \"#d3d3d3\"</code>,</li> <li> <code>lightgrey: \"#d3d3d3\"</code>,</li> <li> <code>lightpink: \"#ffb6c1\"</code>,</li> <li> <code>lightsalmon: \"#ffa07a\"</code>,</li> <li> <code>lightseagreen: \"#20b2aa\"</code>,</li> <li> <code>lightskyblue: \"#87cefa\"</code>,</li> <li> <code>lightslategray: \"#778899\"</code>,</li> <li> <code>lightslategrey: \"#778899\"</code>,</li> <li> <code>lightsteelblue: \"#b0c4de\"</code>,</li> <li> <code>lightyellow: \"#ffffe0\"</code>,</li> <li> <code>lime: \"#00ff00\"</code>,</li> <li> <code>limegreen: \"#32cd32\"</code>,</li> <li> <code>linen: \"#faf0e6\"</code>,</li> <li> <code>magenta: \"#ff00ff\"</code>,</li> <li> <code>maroon: \"#800000\"</code>,</li> <li> <code>mediumaquamarine: \"#66cdaa\"</code>,</li> <li> <code>mediumblue: \"#0000cd\"</code>,</li> <li> <code>mediumorchid: \"#ba55d3\"</code>,</li> <li> <code>mediumpurple: \"#9370db\"</code>,</li> <li> <code>mediumseagreen: \"#3cb371\"</code>,</li> <li> <code>mediumslateblue: \"#7b68ee\"</code>,</li> <li> <code>mediumspringgreen: \"#00fa9a\"</code>,</li> <li> <code>mediumturquoise: \"#48d1cc\"</code>,</li> <li> <code>mediumvioletred: \"#c71585\"</code>,</li> <li> <code>midnightblue: \"#191970\"</code>,</li> <li> <code>mintcream: \"#f5fffa\"</code>,</li> <li> <code>mistyrose: \"#ffe4e1\"</code>,</li> <li> <code>moccasin: \"#ffe4b5\"</code>,</li> <li> <code>navajowhite: \"#ffdead\"</code>,</li> <li> <code>navy: \"#000080\"</code>,</li> <li> <code>oldlace: \"#fdf5e6\"</code>,</li> <li> <code>olive: \"#808000\"</code>,</li> <li> <code>olivedrab: \"#6b8e23\"</code>,</li> <li> <code>orange: \"#ffa500\"</code>,</li> <li> <code>orangered: \"#ff4500\"</code>,</li> <li> <code>orchid: \"#da70d6\"</code>,</li> <li> <code>palegoldenrod: \"#eee8aa\"</code>,</li> <li> <code>palegreen: \"#98fb98\"</code>,</li> <li> <code>paleturquoise: \"#afeeee\"</code>,</li> <li> <code>palevioletred: \"#db7093\"</code>,</li> <li> <code>papayawhip: \"#ffefd5\"</code>,</li> <li> <code>peachpuff: \"#ffdab9\"</code>,</li> <li> <code>peru: \"#cd853f\"</code>,</li> <li> <code>pink: \"#ffc0cb\"</code>,</li> <li> <code>plum: \"#dda0dd\"</code>,</li> <li> <code>powderblue: \"#b0e0e6\"</code>,</li> <li> <code>purple: \"#800080\"</code>,</li> <li> <code>rebeccapurple: \"#663399\"</code>,</li> <li> <code>red: \"#ff0000\"</code>,</li> <li> <code>rosybrown: \"#bc8f8f\"</code>,</li> <li> <code>royalblue: \"#4169e1\"</code>,</li> <li> <code>saddlebrown: \"#8b4513\"</code>,</li> <li> <code>salmon: \"#fa8072\"</code>,</li> <li> <code>sandybrown: \"#f4a460\"</code>,</li> <li> <code>seagreen: \"#2e8b57\"</code>,</li> <li> <code>seashell: \"#fff5ee\"</code>,</li> <li> <code>sienna: \"#a0522d\"</code>,</li> <li> <code>silver: \"#c0c0c0\"</code>,</li> <li> <code>skyblue: \"#87ceeb\"</code>,</li> <li> <code>slateblue: \"#6a5acd\"</code>,</li> <li> <code>slategray: \"#708090\"</code>,</li> <li> <code>slategrey: \"#708090\"</code>,</li> <li> <code>snow: \"#fffafa\"</code>,</li> <li> <code>springgreen: \"#00ff7f\"</code>,</li> <li> <code>steelblue: \"#4682b4\"</code>,</li> <li> <code>tan: \"#d2b48c\"</code>,</li> <li> <code>teal: \"#008080\"</code>,</li> <li> <code>thistle: \"#d8bfd8\"</code>,</li> <li> <code>tomato: \"#ff6347\"</code>,</li> <li> <code>turquoise: \"#40e0d0\"</code>,</li> <li> <code>violet: \"#ee82ee\"</code>,</li> <li> <code>wheat: \"#f5deb3\"</code>,</li> <li> <code>white: \"#ffffff\"</code>,</li> <li> <code>whitesmoke: \"#f5f5f5\"</code>,</li> <li> <code>yellow: \"#ffff00\"</code>,</li> <li> <code>yellowgreen: \"#9acd32\"</code>,</li> </ul> </li> <li> <p><code>mode: str</code>: Mode to use for the image. Default is 'RGBA'.</p> </li> <li><code>size: tuple</code>: Size of the image in pixels (width, height). Default is (1, 1) for changing size afterwards.</li> <li><code>fps: float, optional</code>: Frames per second for the video clip.</li> <li><code>duration: float, optional</code>: Duration of the video clip in seconds.</li> </ul> Attributes: <ul> <li><code>color: str | tuple[int, ...]</code>: The color of the video clip.</li> <li><code>mode: str</code>: The mode of the video clip.</li> <li>Other attributes are inherited from the <code>Data2ImageClip</code> <code>class</code>.</li> </ul> Methods: <p><code>set_size(self, size: tuple[int, int])</code>:</p> <p>Set the size of the video clip.</p> Parameters: <code>size: tuple[int, int]</code>: New size of the video clip in pixels (width, height). Example Usage: <pre><code>color_clip.set_size((800, 600))\n</code></pre> Example Usage: <pre><code># Create a red square video clip (500x500, 30 FPS, 5 seconds):\nred_square = ColorClip(color='red', size=(500, 500), fps=30, duration=5)\n\n# Create a blue fullscreen video clip (1920x1080, default FPS and duration):\nblue_fullscreen = ColorClip(color='blue', size=(1920, 1080))\n\n# Create a green transparent video clip (RGBA mode, 800x600):\ngreen_transparent = ColorClip(color=(0, 255, 0, 0), mode='RGBA', size=(800, 600))\n</code></pre>"},{"location":"reference_manual/clips/video_clips/imageclips/#textclip","title":"TextClip","text":"<code>class</code> <code>vidiopy.TextClip(text: str, font_pth: None | str = None, font_size: int = 20, txt_color: str | tuple[int, ...] = (255, 255, 255, 0), bg_color: str | tuple[int, ...] = (0, 0, 0, 0), fps=None, duration=None)</code> <p>Bases: #!py vidiopy.Data2ImageClip</p> <p>A class representing a text clip to be used in video compositions.</p> Parameters: <ul> <li><code>text (str)</code>: The text content to be displayed in the clip.</li> <li><code>font_pth (None | str, optional)</code>: The file path to the TrueType font file (.ttf). If None, the default system font is used. Defaults to None.</li> <li><code>font_size (int, optional)</code>: The font size for the text. Defaults to 20.</li> <li><code>txt_color (str | tuple[int, ...], optional)</code>: The color of the text specified as either a string (e.g., 'white') or a tuple representing RGBA values. Defaults to (255, 255, 255, 0) (fully transparent white).</li> <li><code>bg_color (str | tuple[int, ...], optional)</code>: The background color of the text clip, specified as either a string (e.g., 'black') or a tuple representing RGBA values. Defaults to (0, 0, 0, 0) (fully transparent black).</li> <li><code>fps (float, optional)</code>: Frames per second of the video. If None, the value is inherited from the parent class. Defaults to None.</li> <li><code>duration (float, optional)</code>: Duration of the video clip in seconds. If None, the value is inherited from the parent class. Defaults to None.</li> </ul> Attributes: <ul> <li><code>font (PIL.ImageFont.FreeTypeFont)</code>: The font object used for rendering the text.</li> <li><code>image (PIL.Image.Image)</code>: The image containing the rendered text.</li> <li><code>fps (float)</code>: Frames per second of the video clip.</li> <li><code>duration (float)</code>: Duration of the video clip in seconds.</li> <li>Other attributes are inherited from the <code>Data2ImageClip</code> <code>class</code>.</li> </ul> Example Usage: <pre><code># Create a TextClip with custom text and styling\ntext_clip = TextClip(\"Contribute to Vidiopy\", font_size=30, txt_color='red', bg_color='blue', fps=24, duration=5.0)\n\n# Use the text clip in a video composition\ncomposition = CompositeVideoClip([other_clip, text_clip])\ncomposition.write_videofile(\"output.mp4\", codec='libx264', fps=24)\n</code></pre>"},{"location":"reference_manual/clips/video_clips/imagesequenceclip/","title":"ImageSequenceClip","text":"<p><code>class</code> <code>vidiopy.VideoClip.ImageSequenceClip</code></p> <p>Bases: <code>vidiopy.VideoClip.VideoClip(sequence, fps=None, duration=None, audio=None)</code></p> <p>A class used to represent a sequence of images as a video clip. This class extends the VideoClip class and provides additional functionality for handling sequences of images.</p> Attributes: <ul> <li> <p><code>clip (tuple[Image.Image, ...])</code>: The sequence of images as a tuple of PIL Images.</p> </li> <li> <p>It inherits all the attributes from the <code>VideoClip</code> class.</p> </li> </ul> Parameters: <ul> <li><code>sequence (str | Path | tuple[Image.Image, ...] | tuple[np.ndarray, ...] | tuple[str | Path, ...])</code>: The sequence to import. It can be a tuple of PIL Images, paths to images, numpy arrays, or a path to a directory.</li> <li><code>fps (int | float | None, optional)</code>: The frames per second of the image sequence clip. If not specified, it is calculated from the <code>duration</code> and the number of images in the <code>sequence</code>.</li> <li><code>duration (int | float | None, optional)</code>: The duration of the image sequence clip in seconds. If not specified, it is calculated from the <code>fps</code> and the number of images in the <code>sequence</code>.</li> <li><code>audio (optional)</code>: The audio of the image sequence clip. If not specified, the image sequence clip will have no audio.</li> </ul> Methods: <p><code>make_frame_array(t)</code></p> <p>Generates a numpy array representation of a specific frame in the image sequence clip.</p> <p>This method calculates the index of the frame for a specific time, retrieves the frame from the image sequence clip, and converts it to a numpy array.</p> <p>Parameters: - <code>t (int | float)</code>: The time of the frame to convert.</p> <p>Returns: - <code>np.ndarray</code>: The numpy array representation of the frame.</p> <p>Requires: - <code>duration</code> or <code>end</code> to be set.</p> <p><code>make_frame_pil(t)</code></p> <p>Generates a PIL Image representation of a specific frame in the image sequence clip.</p> <p>This method calculates the index of the frame for a specific time, retrieves the frame from the image sequence clip, and returns it as a PIL Image.</p> <p>Parameters: - <code>t (int | float)</code>: The time of the frame to convert.</p> <p>Returns: - <code>Image.Image</code>: The PIL Image representation of the frame.</p> <p>Raises: - <code>ValueError</code>: If neither the <code>duration</code> nor the <code>end</code> of the image sequence clip is set.</p> <p>Requires: - <code>duration</code> or <code>end</code> to be set.</p> <p><code>fl_frame_transform(func, *args, **kwargs)</code></p> <p>Applies a function to each frame of the image sequence clip.</p> <p>This method iterates over each frame in the image sequence clip, applies a function to it, and replaces the original frame with the result. The function is expected to take a PIL Image as its first argument and return a PIL Image.</p> <p>Parameters: - <code>func (Callable[..., Image.Image])</code>: The function to apply to each frame. It should take a PIL Image as its first argument and return a PIL Image. - <code>*args</code>: Additional positional arguments to pass to the function. - <code>**kwargs</code>: Additional keyword arguments to pass to the function.</p> <p>Returns: - <code>ImageSequenceClip</code>: The current instance of the <code>ImageSequenceClip</code> class.</p> <p>Example: <pre><code>&gt;&gt;&gt; image_sequence_clip = ImageSequenceClip()\n&gt;&gt;&gt; image_sequence_clip.fl_frame_transform(lambda frame: frame.rotate(90))\n</code></pre></p> <p><code>fl_clip_transform(func, *args, **kwargs)</code></p> <p>Applies a function to each frame of the image sequence clip along with its timestamp.</p> <p>This method iterates over each frame in the image sequence clip, applies a function to it and its timestamp, and replaces the original frame with the result. The function is expected to take a PIL Image and a float as its first two arguments and return a PIL Image.</p> <p>Parameters: - <code>func (Callable[..., Image.Image])</code>: The function to apply to each frame. It should take a PIL Image and a float as its first two arguments and return a PIL Image. - <code>*args</code>: Additional positional arguments to pass to the function. - <code>**kwargs</code>: Additional keyword arguments to pass to the function.</p> <p>Returns: - <code>ImageSequenceClip</code>: The current instance of the <code>ImageSequenceClip</code> class.</p> <p>Raises: - <code>ValueError</code>: If the <code>fps</code> of the image sequence clip is not set.</p> <p>Requires: - <code>fps</code> to be set.</p> <p>Example: <pre><code>&gt;&gt;&gt; image_sequence_clip = ImageSequenceClip()\n&gt;&gt;&gt; image_sequence_clip.fl_clip_transform(lambda frame, t: frame.rotate(90 * t))\n</code></pre></p>"},{"location":"reference_manual/clips/video_clips/mixing_clips/","title":"CompositeVideoCLip","text":"<p><code>def</code> <code>composite_videoclips(clips: Sequence[VideoClip], fps: int | float | None = None, bg_color: tuple[int, ...] = (0, 0, 0, 0), use_bg_clip: bool = False, audio: bool = True, audio_fps=44100)</code></p> <p>Composites multiple video clips into a single video clip.</p> <p>This <code>function</code> takes a <code>sequence</code> of video clips and composites them into a single video clip. The clips are layered on top of each other in the order they appear in the <code>sequence</code>. The background of the composite clip can be a solid color or the first clip in the <code>sequence</code>. The <code>function</code> also handles the positioning of each clip in the composite clip and the audio of the composite clip.</p> Args: <ul> <li><code>clips: Sequence[VideoClip]</code>: The <code>sequence</code> of video clips to composite.</li> <li><code>fps (int | float | None, optional)</code>: The frames per second of the composite clip. If not specified, it is set to the maximum fps of the clips in the <code>sequence</code> or raises a ValueError if none of the clips have fps set.</li> <li><code>bg_color (tuple[int, ...], optional)</code>: The background color of the composite clip as a tuple of integers representing RGBA values. Default is (0, 0, 0, 0) which is transparent.</li> <li><code>use_bg_clip (bool, optional)</code>: Whether to use the first clip in the <code>sequence</code> as the background of the composite clip. Default is False.</li> <li><code>audio (bool, optional)</code>: Whether to include audio in the composite clip. If True, the audio of the clips in the <code>sequence</code> is also composited. Default is True.</li> <li><code>audio_fps (int, optional)</code>: The frames per second of the audio of the composite clip. Default is 44100.</li> </ul> Returns: <code>ImageSequenceClip</code>: The composite video clip as an instance of the <code>ImageSequenceClip</code> class. Raises: <ul> <li><code>ValueError</code>: If neither fps nor duration is set for any of the clips in the <code>sequence</code>.</li> <li><code>ValueError</code>: If the position of a clip in the composite clip is not specified correctly.</li> <li><code>TypeError</code>: If the position of a clip in the composite clip is not of the correct type.</li> </ul> Example: <pre><code>&gt;&gt;&gt; clip1 = VideoClip(...)\n&gt;&gt;&gt; clip2 = VideoClip(...)\n&gt;&gt;&gt; composite_clip = composite_videoclips([clip1, clip2], fps=24)\n</code></pre> Note: This <code>function</code> uses the <code>`#!py ImageSequenceClip</code> class to create the composite video clip and the composite_audioclips <code>function</code> to composite the audio of the clips."},{"location":"reference_manual/clips/video_clips/mixing_clips/#concatenatevideoclips","title":"ConcatenateVideoClips","text":"<p><code>def</code> <code>concatenate_videoclips(clips: Sequence[VideoClip], transparent: bool = False, fps: int | float | None = None, scaling_strategy: str = \"scale_same\", transition: ( VideoClip | Callable[[Image.Image, Image.Image, int | float], VideoClip] | None ) = None, audio: bool = True, audio_fps: int | None = None):</code></p> <p>Concatenates multiple video clips into a single video clip.</p> <p>This function takes a sequence of video clips and concatenates them into a single video clip. The clips are appended one after the other in the order they appear in the sequence. The function also handles the scaling of each clip in the concatenated clip and the audio of the concatenated clip.</p> Args: <ul> <li><code>clips (Sequence[VideoClip])</code>: The sequence of video clips to concatenate.</li> <li><code>transparent (bool, optional)</code>: Whether to use a transparent background for the concatenated clip. Default is False.</li> <li><code>fps (int | float | None, optional)</code>: The frames per second of the concatenated clip. If not specified, it is set to the maximum fps of the clips in the sequence or raises a ValueError if none of the clips have fps set.</li> <li><code>scaling_strategy (bool |</code> None, optional): The scaling strategy to use for the clips in the concatenated clip. If 'scale_up', the clips are scaled up to fit the size of the concatenated clip. If 'scale_down', the clips are scaled down to fit the size of the concatenated clip. If 'scale_same', the clips are not scaled. Default is 'scale_same'.</li> <li><code>transition (VideoClip | Callable[[Image.Image, Image.Image, int | float], VideoClip] | None, optional)</code>: The transition to use between the clips in the concatenated clip. If a VideoClip, it is used as the transition. If a callable, it is called with the last frame of the previous clip, the first frame of the next clip, and the duration of the transition to generate the transition. If None, no transition is used. Default is None.</li> <li><code>audio (bool, optional)</code>: Whether to include audio in the concatenated clip. If True, the audio of the clips in the sequence is also concatenated. Default is True.</li> <li><code>audio_fps (int | None, optional)</code>: The frames per second of the audio of the concatenated clip. Default is None.</li> </ul> Returns: <code>ImageSequenceClip</code>: The concatenated video clip as an instance of the <code>ImageSequenceClip</code> class. <p>Raises:     - <code>ValueError</code>: If neither fps nor duration is set for any of the clips in the sequence.     - <code>ValueError</code>: If the size of a clip in the concatenated clip is not specified correctly.     - <code>TypeError</code>: If the scaling strategy of a clip in the concatenated clip is not of the correct type.</p> Example: <pre><code>&gt;&gt;&gt; clip1 = VideoClip(...)\n&gt;&gt;&gt; clip2 = ImageClip(...)\n&gt;&gt;&gt; concatenated_clip = concatenate_videoclips([clip1, clip2], fps=24)\n</code></pre> Note: This function uses the <code>ImageSequenceClip</code> class to create the concatenated video clip and the concatenate_audioclips function to concatenate the audio of the clips."},{"location":"reference_manual/clips/video_clips/videoclip/","title":"VideoClip","text":"<p><code>class</code> <code>vidiopy.VideoClip.VideoClip</code></p> <p>Base: <code>vidiopy.Clip.Clip</code></p> <p>A VideoClip is a Base Class for all Video And Image clips (<code>VideoFileClip</code>, <code>ImageClip</code> and <code>ImageSequenceClip</code>)</p> <p>See <code>VideoFileClip</code>, <code>ImageClip</code> etc. for more user-friendly classes.</p> Attributes: <p>_st: <code>float | int</code></p> The start time of the clip (in seconds). <p>_ed: <code>float | int | None</code></p> The end time of the clip (in seconds). <p>_dur: <code>float | int | None</code></p> <p>The Duration of the clip (in seconds).</p> Warning: Not Real Duration <p>It Many not equal to <code>video.end - video.start</code>. It is the Original Duration In which Video Is imported or any thing else.</p> <p>fps: <code>float | int | None</code></p> The FPS(Frame per Second) of the Video. <p>size: <code>tuple[int, int]</code></p> The size of the clip, (width,height), in pixels. <p>audio: <code>AudioClip | None</code></p> Audio in the Video. <p>pos: <code>Callable[[float | int], tuple[int | str | float, int | str | float]]</code></p> A function <code>t-&gt;(x,y)</code> where x,y is the position of the clip when it is composed with other clips. See VideoClip.set_pos for more details. <p>relative_pos: <code>bool</code></p> A Bool Which Determine whether the pos will output a relative position or in pixel. Properties: <p>start: <code>float | int</code></p> The start time of the clip (in seconds). <p>end: <code>float | int | None</code></p> The end time of the clip (in seconds). <p>duration: <code>float | int | None</code></p> <p>The Duration of the clip (in seconds).</p> Warning: Not Real Duration <p>It Many not equal to <code>video.end - video.start</code>. It is the Original Duration In which Video Is imported or any thing else.</p> <p>width | w: <code>int</code></p> The width of the clip, in pixels. <p>height | h: <code>int</code></p> The height of the clip, in pixels. <p>aspect_ratio: <code>Fraction</code></p> The aspect ratio of the clip, (width / height). methods: <p><code>set_start(self, value: int | float) -&gt; VideoClip</code></p> <p>The set_start method is used to set the start time of the video clip. It Changes _st attribute of the VideoClip.</p> Args: <code>value: int | float</code>: The start time of the video clip. Returns: <code>VideoClip</code>: The instance of the VideoClip after setting the start time. <p><code>set_end(self, value: int | float) -&gt; VideoClip</code></p> <p>The set_end method is used to set the end time of the video clip. It Changes _ed attribute of the VideoClip.</p> Args: <code>value: int | float</code>: The end time of the video clip. Returns: <code>VideoClip</code>: The instance of the VideoClip after setting the end time. <p><code>set_duration(self, value: int | float) -&gt; VideoClip</code></p> <p>Setter for the duration of the video clip. it raises a ValueError since duration is not allowed to be set. but you can change the duration using <code>clip._dur = value</code> or the <code>_set_duration</code> method.</p> Args: <code>dur: int | float</code>: The duration to set for the video clip. Returns: <code>NoReturn</code>: Raises a <code>ValueError</code> since duration is not allowed to be set. Raises: <code>ValueError</code>: If an attempt is made to set the duration, a <code>ValueError</code> is raised. <p><code>_set_duration(self, value: int | float) -&gt; VideoClip</code></p> <p>Private method to set the duration of the video clip. It Changes _dur attribute of the VideoClip.</p> Args: <code>value: int | float</code>: The duration to set for the video clip. Returns: <code>VideoClip</code>: The instance of the <code>VideoClip</code> after setting the duration. <p><code>set_position(self, pos: (tuple[int | float | str, int | float | str] | list[int | float | str] | Callable[[float | int], tuple[int | float | str, int | float | str]]), relative=False) -&gt; Self:</code></p> <p>Sets the position of the video clip. This is useful for the concatenate method, where the position of the video clip is used  to set it on other clip. This method allows the position of the video clip to be set either as a fixed tuple of coordinates, or as a function that returns a tuple of coordinates at each time. The position can be set as absolute or relative to the size of the clip using the relative.</p> Note: <ul> <li>It Should Be the coordinates of the Video on the top left corner.</li> <li>If relative is True, the position should be between the 0.0 &amp; 1.0.</li> <li>If relative is False, the position should be between the 0 &amp; width or height of the video.</li> </ul> Parameters: <code>pos: tuple | Callable</code>: The position to set for the video clip. This can be either: <ul> <li>a tuple of two integers or floats, representing the x and y coordinates of the position, or</li> <li>a callable that takes a single float or integer argument (representing the time) and returns a tuple of two integers or floats, representing the x and y coordinates of the position.</li> </ul> <code>relative (bool, optional)</code>: Whether the position is relative to the size of the clip. If True, the position is interpreted as a fraction of the clip's width and height. Defaults to False. Raises: <code>TypeError</code>: If <code>pos</code> is not a tuple or a callable. Returns: <code>self</code>: Returns the instance of the class. <p><code>set_audio(self, audio: AudioClip | None) -&gt; Self</code>:</p> <p>Sets the audio for the video clip.</p> <p>This method assigns the provided audio clip to the video clip. If the audio clip is not <code>None</code>, it also sets the start and end times of the audio clip to match the video clip's start and end times.</p> Parameters: <code>audio: AudioClip | None</code>: The audio clip to be set to the video clip. If <code>None</code>, no audio is set. Returns: <code>Self</code>: Returns the instance of the class with updated audio clip. <p><code>without_audio(self) -&gt; Self</code>:</p> <p>Removes the audio from the current VideoClip instance.</p> <p>This method sets the 'audio' attribute of the VideoClip instance to None, effectively removing any audio that the clip might have.</p> Returns: VideoClip: The same instance of the VideoClip but without any audio. This allows for method chaining. Example: <pre><code>&gt;&gt;&gt; clip = VideoClip(...)\n&gt;&gt;&gt; clip_without_audio = clip.without_audio()\n</code></pre> Note: This method modifies the VideoClip instance in-place. If you want to keep the original clip with audio, consider making a copy before calling this method. <p><code>set_fps(self, fps: int | float) -&gt; Self</code>:</p> <p>Set the frames per second (fps) for the video clip.</p> <p>This method allows you to set the fps for the video clip. The fps value determines how many frames are shown per second during playback. A higher fps value results in smoother video playback.</p> Parameters: <code>fps: int | float</code>: The frames per second value to set. This can be an integer or a float. For example, a value of 24 would mean 24 frames are shown per second. Raises: <code>TypeError</code>: If the provided fps value is not an integer or a float. Returns: <code>Self</code>: Returns the instance of the class, allowing for method chaining. Example: <pre><code>&gt;&gt;&gt; clip = VideoClip()\n&gt;&gt;&gt; clip.set_fps(24)\n</code></pre> <p><code>make_frame_array(self, t) -&gt; np.ndarray</code>:</p> <p>Generate a frame at time <code>t</code> as a NumPy array.</p> <p>This method is intended to be overridden in subclasses. It should return a NumPy array representing the frame at the given time.</p> Parameters: <code>t: float</code>: The time at which to generate the frame. Raises: <code>NotImplementedError</code>: If the method is not overridden in a subclass. Returns: <code>np.ndarray</code>: A NumPy array representing the frame at time <code>t</code>. Example: <pre><code>&gt;&gt;&gt; clip = VideoClipSubclass()\n&gt;&gt;&gt; frame = clip.make_frame_array(0.5)\n</code></pre> <p><code>make_frame_pil(self, t) -&gt; np.ndarray</code>:</p> <p>Generate a frame at time <code>t</code> as a NumPy array.</p> <p>This method is intended to be overridden in subclasses. It should return a PIL representing the frame at the given time.</p> Parameters: <code>t: float</code>: The time at which to generate the frame. Raises: <code>NotImplementedError</code>: If the method is not overridden in a subclass. Returns: <code>np.ndarray</code>: A NumPy array representing the frame at time <code>t</code>. Example: <pre><code>&gt;&gt;&gt; clip = VideoClipSubclass()\n&gt;&gt;&gt; frame = clip.make_frame_pil(0.5)\n</code></pre> <p><code>get_frame(self, t: int | float, is_pil=None) -&gt; np.ndarray | Image.Image</code>:</p> <p>Get a frame at time <code>t</code>.</p> <p>This method returns a frame at the given time <code>t</code>. The frame can be returned as a NumPy array or a PIL Image, depending on the value of <code>is_pil</code>.</p> Parameters: <code>t: int | float</code>: The time at which to get the frame. <code>is_pil (bool, optional)</code>: If <code>True</code>, the frame is returned as a PIL Image. If <code>False</code> or None, the frame is returned as a NumPy array. Defaults to None. Raises: <code>ValueError</code>: If <code>is_pil</code> is not <code>True</code>, <code>False</code>, or None. Returns: <code>np.ndarray | Image.Image</code>: The frame at time <code>t</code> as a NumPy array or a PIL Image. Example: <pre><code>&gt;&gt;&gt; clip = VideoClip()\n&gt;&gt;&gt; frame_array = clip.get_frame(0.5)\n&gt;&gt;&gt; frame_pil = clip.get_frame(0.5, is_pil=True)\n</code></pre> <p><code>iterate_frames_pil_t(self, fps: int | float) -&gt; Generator[Image.Image, Any, None]</code>:</p> <p>Iterate over frames as PIL Images at a given frames per second (fps).</p> <p>This method generates frames at a given fps as PIL Images. The frames are generated from the start of the clip to the end or duration, whichever is set.</p> Parameters: <code>fps: int | float</code>: The frames per second at which to generate frames. Raises: <code>ValueError</code>: If neither end nor duration is set. Yields: <code>Image.Image</code>: The next frame as a PIL Image. Example: <pre><code>&gt;&gt;&gt; clip = VideoClip()\n&gt;&gt;&gt; for frame in clip.iterate_frames_pil_t(24):\n...     # Do something with frame\n</code></pre> <p><code>iterate_frames_array_t(self, fps: int | float) -&gt; Generator[np.ndarray, Any, None]</code>:</p> <p>Iterate over frames as NumPy arrays at a given frames per second (fps).</p> <p>This method generates frames at a given fps as NumPy arrays. The frames are generated from the start of the clip to the end or duration, whichever is set.</p> Parameters: <code>fps: int | float</code>: The frames per second at which to generate frames. Raises: <code>ValueError</code>: If neither end nor duration is set. Yields: <code>np.ndarray</code>: The next frame as a NumPy array. Example: <pre><code>&gt;&gt;&gt; clip = VideoClip()\n&gt;&gt;&gt; for frame in clip.iterate_frames_array_t(24):\n...     # Do something with frame\n</code></pre> <p><code>sub_clip_copy(self, t_start: int | float | None = None, t_end: int | float | None = None) -&gt; Self</code>:</p> <p>Returns a subclip of the clip.copy, starting at time t_start (in seconds).</p> Parameters: <code>t_start: int | float | None, optional</code>: The start time of the subclip in seconds. Defaults to None. <code>t_end: int | float | None, optional</code>: The end time of the subclip in seconds. Defaults to None. Returns: <code>Self</code>: The subclip of the clip. Raises: <code>NotImplementedError</code>: If the method is not overridden in a subclass. Example: <pre><code>&gt;&gt;&gt; clip = VideoClip()\n&gt;&gt;&gt; subclip = clip.sub_clip_copy(t_start=1.5, t_end=3.5)\n</code></pre> <p><code>sub_clip(self, t_start: int | float | None = None, t_end: int | float | None = None) -&gt; Self</code>:</p> <p>Returns a subclip of the clip, starting at time t_start and ending at time t_end.</p> Parameters: <code>t_start: int | float | None, optional</code>: The start time of the subclip in seconds. Defaults to None. <code>t_end: int | float | None, optional</code>: The end time of the subclip in seconds. Defaults to None. Returns: <code>Self</code>: The subclip of the clip. Raises: <code>NotImplementedError</code>: If the method is not overridden in a subclass. Example: <pre><code>&gt;&gt;&gt; clip = VideoClip()\n&gt;&gt;&gt; subclip = clip.sub_clip(t_start=1.5, t_end=3.5)\n</code></pre> <p><code>fl_frame_transform(self, func, *args, **kwargs) -&gt; Self</code>:</p> <p>Apply a frame transformation function to each frame of the video clip.</p> <p>This method calls the provided function <code>func</code> on each frame of the clip and applies the transformation. The transformed frames are then stored in a list and assigned back to the clip.</p> Parameters: <code>func</code>: The frame transformation function to be applied. <code>*args</code>: Additional positional arguments to be passed to the transformation function. <code>**kwargs</code>: Additional keyword arguments to be passed to the transformation function. Returns: <code>Self</code>: The modified video clip object. Example: <pre><code>&gt;&gt;&gt; def grayscale(frame):\n&gt;&gt;&gt;     # Convert frame to grayscale\n&gt;&gt;&gt;     return cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n&gt;&gt;&gt;\n&gt;&gt;&gt; clip = VideoClip()\n&gt;&gt;&gt; clip.fl_frame_transform(grayscale)\n</code></pre> Note: This method is meant to be overridden in the subclass. If not overridden, it raises a NotImplementedError. The transformation function <code>func</code> should accept a single frame as the first argument and return the transformed frame. <p><code>fl_time_transform(self, func_t: Callable[[int | float], int | float]) -&gt; Self</code>:</p> <p>Apply a time transformation function to the clip.</p> <p>This method modifies the <code>make_frame_array</code> and <code>make_frame_pil</code> methods to apply a time transformation function <code>func_t</code> to the time <code>t</code> before generating the frame. This can be used to speed up, slow down, or reverse the clip, among other things.</p> <p>If the clip has audio, the same time transformation is applied to the audio.</p> Parameters: <code>func_t (Callable[[int | float], int | float])</code>: The time transformation function to apply. This function should take a time <code>t</code> and return a new time. Returns: <code>Self</code>: Returns the instance of the class, allowing for method chaining. Example: <pre><code>&gt;&gt;&gt; clip = VideoClip()\n&gt;&gt;&gt; clip.fl_time_transform(lambda t: 2*t)  # Speed up the clip by a factor of 2\n</code></pre> <p><code>fx(self, func: Callable[..., Self], *args, **kwargs) -&gt; Self</code>:</p> <p>Apply an effect function to the clip.</p> <p>This method applies an effect function <code>func</code> to the clip. The effect function should take the clip as its first argument, followed by any number of positional and keyword arguments.</p> <p>The effect function should return a new clip, which is then returned by this method.</p> Parameters: <code>func (Callable[..., Self])</code>: The effect function to apply. This function should take the clip as its first argument, followed by any number of positional and keyword arguments. <code>*args</code>: Positional arguments to pass to the effect function. <code>**kwargs</code>: Keyword arguments to pass to the effect function. Returns: <code>Self</code>: The new clip returned by the effect function. Example: <pre><code>&gt;&gt;&gt; clip = VideoClip()\n&gt;&gt;&gt; clip.fx(effect_function, arg1, arg2, kwarg1=value1)\n</code></pre> <p><code>sub_fx(self, func: Callable[..., Self], *args, start_t: int | float | None = None, end_t: int | float | None = None, **kwargs) -&gt; Self</code>:</p> <p>Apply an effect function to a subclip of the clip.</p> <p>This method creates a subclip from <code>start_t</code> to <code>end_t</code>, applies an effect function <code>func</code> to the subclip, and returns the modified subclip.</p> <p>The effect function should take the clip as its first argument, followed by any number of positional and keyword arguments.</p> Parameters: <code>func (Callable[..., Self])</code>: The effect function to apply. This function should take the clip as its first argument, followed by any number of positional and keyword arguments. <code>*args</code>: Positional arguments to pass to the effect function. <code>start_t (int | float | None, optional)</code>: The start time of the subclip. If None, the start of the clip is used. Defaults to None. <code>end_t (int | float | None, optional)</code>: The end time of the subclip. If None, the end of the clip is used. Defaults to None. <code>**kwargs</code>: Keyword arguments to pass to the effect function. Returns: <code>Self</code>: The modified subclip. Example: <pre><code>&gt;&gt;&gt; clip = VideoClip()\n&gt;&gt;&gt; subclip = clip.sub_fx(effect_function, arg1, arg2, start_t=1, end_t=2, kwarg1=value1)\n</code></pre> <p><code>_sync_audio_video_s_e_d(self) -&gt; Self</code>:</p> <p>Synchronizes the audio and video start, end, and duration attributes.</p> <p>This method is used to ensure that the audio and video parts of a clip are in sync. It sets the start, end, and original duration of the audio to match the video.</p> Returns: <code>Self</code>: Returns the instance of the class with updated audio attributes. Raises: None Example: <pre><code>&gt;&gt;&gt; video_clip = VideoClip()\n&gt;&gt;&gt; video_clip._sync_audio_video_s_e_d()\n</code></pre> Note: This is an internal method, typically not meant to be used directly by the user. <p><code>write_videofile(self, filename, fps=None, codec=None, bitrate=None, audio=True, audio_fps=44100, preset=\"medium\", pixel_format=None, audio_codec=None, audio_bitrate=None, threads=None, ffmpeg_params: dict[str, str] | None = None, logger=\"bar\", over_write_output=True) -&gt; Self</code>:</p> <p>Writes the video clip to a file.</p> <p>This method generates video frames, processes them, and writes them to a file. If audio is present in the clip, it is also written to the file.</p> Args: <code>filename (str)</code>: The name of the file to write. <code>fps (int, optional)</code>: The frames per second to use for the output video. If not provided, the fps of the video clip is used. <code>codec (str, optional)</code>: The codec to use for the output video. <code>bitrate (str, optional)</code>: The bitrate to use for the output video. <code>audio (bool, optional)</code>: Whether to include audio in the output video. Defaults to True. <code>audio_fps (int, optional)</code>: The frames per second to use for the audio. Defaults to 44100. <code>preset (str, optional)</code>: The preset to use for the output video. Defaults to \"medium\". <code>pixel_format (str, optional)</code>: The pixel format to use for the output video. <code>audio_codec (str, optional)</code>: The codec to use for the audio. <code>audio_bitrate (str, optional)</code>: The bitrate to use for the audio. <code>threads (int, optional)</code>: The number of threads to use for writing the video file. <code>ffmpeg_params (dict[str, str] | None, optional)</code>: Additional parameters to pass to ffmpeg. <code>logger (str, optional)</code>: The logger to use. Defaults to \"bar\". <code>over_write_output (bool, optional)</code>: Whether to overwrite the output file if it already exists. Defaults to True. Returns: <code>Self</code>: Returns the instance of the class. Raises: <code>Exception</code>: If fps is not provided and not set in the video clip. Example: <pre><code>&gt;&gt;&gt; video_clip = VideoClip()\n&gt;&gt;&gt; video_clip.write_videofile(\"output.mp4\")\n</code></pre> Note: This method uses ffmpeg to write the video file. <p><code>write_videofile_subclip(self, filename, start_t: int | float | None = None, end_t: int | float | None = None, fps=None, codec=None, bitrate=None, audio=True, audio_fps=44100, preset=\"medium\", pixel_format=None, audio_codec=None, audio_bitrate=None, write_logfile=False, verbose=True, threads=None, ffmpeg_params: dict[str, str] | None = None, logger=\"bar\", over_write_output=True) -&gt; Self</code>:</p> <p>Writes a subclip of the video clip to a file.</p> <p>This method generates video frames for a specific part of the video (subclip), processes them, and writes them to a file. If audio is present in the clip, it is also written to the file.</p> Args: <code>filename (str)</code>: The name of the file to write. <code>start_t (int | float | None, optional)</code>: The start time of the subclip. If not provided, the start of the video is used. <code>end_t (int | float | None, optional)</code>: The end time of the subclip. If not provided, the end of the video is used. <code>fps (int, optional)</code>: The frames per second to use for the output video. If not provided, the fps of the video clip is used. <code>codec (str, optional)</code>: The codec to use for the output video. <code>bitrate (str, optional)</code>: The bitrate to use for the output video. <code>audio (bool, optional)</code>: Whether to include audio in the output video. Defaults to True. <code>audio_fps (int, optional)</code>: The frames per second to use for the audio. Defaults to 44100. <code>preset (str, optional)</code>: The preset to use for the output video. Defaults to \"medium\". <code>pixel_format (str, optional)</code>: The pixel format to use for the output video. <code>audio_codec (str, optional)</code>: The codec to use for the audio. <code>audio_bitrate (str, optional)</code>: The bitrate to use for the audio. <code>write_logfile (bool, optional)</code>: Whether to write a logfile. Defaults to False. <code>verbose (bool, optional)</code>: Whether to print verbose output. Defaults to True. <code>threads (int, optional)</code>: The number of threads to use for writing the video file. <code>ffmpeg_params (dict[str, str] | None, optional)</code>: Additional parameters to pass to ffmpeg. <code>logger (str, optional)</code>: The logger to use. Defaults to \"bar\". <code>over_write_output (bool, optional)</code>: Whether to overwrite the output file if it already exists. Defaults to True. Returns: <code>Self</code>: Returns the instance of the class. Raises: <code>Exception</code>: If fps is not provided and not set in the video clip. Example: <pre><code>&gt;&gt;&gt; video_clip = VideoClip()\n&gt;&gt;&gt; video_clip.write_videofile_subclip(\"output.mp4\", start_t=10, end_t=20)\n</code></pre> Note: This method uses ffmpeg to write the video file. <p><code>write_image_sequence(self, nformat: str, fps: int | float | None = None, dir=\".\") -&gt; Self</code>:</p> <p>Writes the frames of the video clip as an image sequence.</p> <p>This method generates video frames, processes them, and writes them as images to a directory. The images are named by their frame number and the provided format.</p> Args: <code>nformat (str)</code>: The format to use for the output images. <code>fps (int | float | None, optional)</code>: The frames per second to use for the output images. If not provided, the fps of the video clip is used. <code>dir (str, optional)</code>: The directory to write the images to. Defaults to the current directory. Returns: <code>Self</code>: Returns the instance of the class. Raises: <code>ValueError</code>: If fps is not provided and fps and duration are not set in the video clip. Example: <pre><code>&gt;&gt;&gt; video_clip = VideoClip()\n&gt;&gt;&gt; video_clip.write_image_sequence(\"png\", fps=24, dir=\"frames\")\n</code></pre> Note: This method uses ffmpeg to write the images. <p><code>save_frame(self, t: int | float, filename: str) -&gt; Self</code>:</p> <p>Saves a specific frame of the video clip as an image.</p> <p>This method generates a video frame for a specific time, processes it, and writes it as an image to a file.</p> Args: <code>t (int | float)</code>: The time of the frame to save. <code>filename (str)</code>: The name of the file to write. Returns: <code>Self</code>: Returns the instance of the class. Example: <pre><code>&gt;&gt;&gt; video_clip = VideoClip()\n&gt;&gt;&gt; video_clip.save_frame(10, \"frame10.png\")\n</code></pre> Note: This method uses ffmpeg to write the image. <p><code>to_ImageClip(self, t: int | float)</code>:</p> <p>Converts a specific frame of the video clip to an ImageClip.</p> <p>This method generates a video frame for a specific time, processes it, and converts it to an ImageClip.</p> Args: <code>t (int | float)</code>: The time of the frame to convert. Returns: <code>Data2ImageClip</code>: The converted ImageClip. Raises: None Example: <pre><code>&gt;&gt;&gt; video_clip = VideoClip()\n&gt;&gt;&gt; image_clip = video_clip.to_ImageClip(10)\n</code></pre> Note: This method uses ffmpeg to generate the frame and then converts it to an ImageClip."},{"location":"reference_manual/clips/video_clips/videofileclip/","title":"VideoFileClip","text":"<p><code>class</code> <code>vidiopy.VideoFileClip(filename: str, audio: bool = True, ffmpeg_options: dict | None = None)</code></p> <p>Bases: <code>vidiopy.VideoClip</code></p> <p>All Methods and properties of the <code>VideoClip</code> class are available.</p> <p>A video clip originating from a Video file.</p> Parameters: <p>filename: str</p> The name of the video file, as a string or a path-like object. It can have any extension supported by ffmpeg. All Sported extensions <ul> <li>.mp4</li> <li>.avi</li> <li>.mov</li> <li>.mkv</li> <li>.webm</li> <li>.flv</li> <li>.wmv</li> <li>.3gp</li> <li>.ogg</li> <li>.ogv</li> <li>.mts</li> <li>.m2ts</li> <li>.ts</li> <li>.vob</li> <li>.mpg</li> <li>.mpeg</li> <li>.m2v</li> <li>.m4v</li> <li>.mxf</li> <li>.dv</li> <li>.f4v</li> <li>.gif</li> <li>.mp3</li> <li>.wav</li> <li>.flac</li> <li>.ogg</li> <li>.m4a</li> <li>.wma</li> <li>.aac</li> <li>.ac3</li> <li>.alac</li> <li>.aiff</li> <li>.amr</li> <li>.au</li> <li>.mka</li> <li>.mp2</li> <li>.mpa</li> <li>.opus</li> <li>.ra</li> <li>.tta</li> <li>.wv</li> <li>.weba</li> <li>.webm</li> <li>.webvtt</li> <li>.srt ETC.</li> </ul> <p><code>audio: bool</code> Default: <code>True</code></p> Set to <code>False</code> if the clip doesn\u2019t have any audio or if you do not wish to read the audio. <p><code>ffmpeg_options: dict | None</code> Default: <code>None</code></p> A dictionary of options to be passed to ffmpeg when generating the clip\u2019s audio. If <code>None</code>, the default options will be used. If you want to pass options to the video part of the clip, you will have to use the <code>vidiopy.VideoFileClip.set_make_frame</code> method. Attributes: <p><code>clip</code>:</p> The Numpy array of the clip\u2019s video frames. <p>Read docs for <code>Clip()</code> and <code>VideoClip()</code> for other, more generic, attributes.</p> Methods: <p><code>fl_frame_transform(self, func, *args, **kwargs) -&gt; Self</code>:</p> <p>Applies a function to each frame of the video clip.</p> <p>This method iterates over each frame in the video clip, applies a function to it, and replaces the original frame with the result.</p> Args: <code>func (callable)</code>: The function to apply to each frame. It should take an Image as its first argument, and return an Image. <code>*args</code>: Additional positional arguments to pass to func. <code>**kwargs</code>: Additional keyword arguments to pass to func. Returns: <code>Self</code>: Returns the instance of the class with updated frames. Raises: None Example: <pre><code>&gt;&gt;&gt; video_clip = VideoClip()\n&gt;&gt;&gt; def invert_colors(image):\n...     return ImageOps.invert(image)\n&gt;&gt;&gt; video_clip.fl_frame_transform(invert_colors)\n</code></pre> Note: This method requires the start and end of the video clip to be set. <p><code>fl_clip_transform(self, func, *args, **kwargs) -&gt; Self</code>:</p> <p>Applies a function to each frame of the video clip along with its timestamp.</p> <p>This method iterates over each frame in the video clip, applies a function to it and its timestamp, and replaces the original frame with the result.</p> Args: <code>func (callable)</code>: The function to apply to each frame. It should take an Image and a float (representing the timestamp) as its first two arguments, and return an Image. <code>*args</code>: Additional positional arguments to pass to func. <code>**kwargs</code>: Additional keyword arguments to pass to func. Returns: <code>Self</code>: Returns the instance of the class with updated frames. Raises: None Example: <pre><code>&gt;&gt;&gt; video_clip = VideoClip()\n&gt;&gt;&gt; def add_timestamp(image, timestamp):\n...     draw = ImageDraw.Draw(image)\n...     draw.text((10, 10), str(timestamp), fill=\"white\")\n...     return image\n&gt;&gt;&gt; video_clip.fl_clip_transform(add_timestamp)\n</code></pre> Note: This method requires the fps of the video clip to be set. <p><code>make_frame_array(self, t: int | float) -&gt; np.ndarray</code>:</p> <p>Generates a numpy array representation of a specific frame in the video clip.</p> <p>This method calculates the index of the frame for a specific time, retrieves the frame from the video clip, and converts it to a numpy array.</p> Args: <code>t (int | float)</code>: The time of the frame to convert. Returns: <code>np.ndarray</code>: The numpy array representation of the frame. Raises: <code>ValueError</code>: If the duration of the video clip is not set. Example: <pre><code>&gt;&gt;&gt; video_clip = VideoClip()\n&gt;&gt;&gt; frame_array = video_clip.make_frame_array(10)\n</code></pre> Note: This method requires the duration of the video clip to be set. <p><code>make_frame_pil(self, t: int | float) -&gt; Image.Image</code>:</p> <p>Generates a PIL Image representation of a specific frame in the video clip.</p> <p>This method calculates the index of the frame for a specific time, retrieves the frame from the video clip, and returns it as a PIL Image.</p> Args: <code>t (int | float)</code>: The time of the frame to convert. Returns: <code>Image.Image</code>: The PIL Image representation of the frame. Raises: <code>ValueError</code>: If the duration of the video clip is not set. Example: <pre><code>&gt;&gt;&gt; video_clip = VideoClip()\n&gt;&gt;&gt; frame_image = video_clip.make_frame_pil(10)\n</code></pre> Note: This method requires the duration of the video clip to be set. <p><code>_import_video_clip(self, file_name: str, ffmpeg_options: dict | None = None) -&gt; tuple</code>:</p> <p>Imports a video clip from a file using ffmpeg.</p> <p>This method reads a video file using ffmpeg, converts each frame to a PIL Image, and returns a tuple of the images and the fps of the video.</p> Args: <code>file_name (str)</code>: The name of the video file to import. <code>ffmpeg_options (dict | None, optional)</code>: Additional options to pass to ffmpeg. Defaults to None. Returns: <code>tuple</code>: A tuple of the frames as PIL Images and the fps of the video. Raises: None Example: <pre><code>&gt;&gt;&gt; video_clip = VideoClip()\n&gt;&gt;&gt; frames, fps = video_clip._import_video_clip(\"video.mp4\")\n</code></pre> Note: This method uses ffmpeg to read the video file. It is a private method and not intended for external use."}]}